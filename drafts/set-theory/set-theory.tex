\documentclass[11pt]{scrreprt}
\input{../../tex/preamble}
\addbibresource{../../references.bib}

\newcommand{\CH}{\mathsf{CH}}
\newcommand{\ZFC}{\mathsf{ZFC}}

\newcommand{\Name}{\text{Name}}
\newcommand{\Po}{\mathbb P}
\newcommand{\nrank}{\opname{n-rank}} % ranks

\newcommand{\EmptySet}{\mathrm{EmptySet}}
\newcommand{\PowerSet}{\mathrm{PowerSet}}
\newcommand{\Pairing}{\mathrm{Pairing}}
\newcommand{\Infinity}{\mathrm{Infinity}}
\newcommand{\Extensionality}{\mathrm{Extensionality}}
\newcommand{\Foundation}{\mathrm{Foundation}}
\newcommand{\Union}{\mathrm{Union}}
\newcommand{\Comprehension}{\mathrm{Comprehension}}
\newcommand{\Replacement}{\mathrm{Replacement}}

\usepackage{mathrsfs}

\newcommand\MM{\mathscr M}
\newcommand\llex{<_{\text{lex}}}

\DeclareMathOperator{\cof}{cof}

\def\asydir{}


\begin{document}
\title{Set Theory}
\maketitle

\chapter{Zermelo-Franklin with Choice}
Chapter $2\half$ of \cite{ref:msci} has a nice description of this.

\section{The Ultimate Functional Equation}
In abstract mathematics, we often define structures by what \emph{properties}
they should have; for example, a group is a set and a binary operation
satisfying so-and-so axioms, while a metric space is a set and a distance function
satisfying so-and-so axioms.

Nevertheless, these definitions rely on previous definitions.
The colorful illustration of \cite{ref:msci} on this:
\begin{itemize}
	\ii A \emph{vector space} is an abelian group with\dots
	\ii An \emph{abelian group} has a binary operation such that\dots
	\ii A \emph{binary operation} on a set is\dots
	\ii A \emph{set} is \dots
\end{itemize}
and so on.

We have to stop at some point, because infinite lists of definitions are bad.
The stopping turns out to be a set, ``defined'' by properties.
The trick is that we never actually define what a set is,
but nonetheless postulate that these sets satisfy certain properties:
these are the $\ZFC$ axioms.
Loosely, $\ZFC$ can be thought of as the \emph{ultimate functional equation}.

Before talking about what these axioms are, I should talk about the caveats.

\section{Cantor's Paradox}
Intuitively, a set is an unordered collection of elements.
Two sets are equal if they share the same elements:
\[
	\left\{ x \mid x \text{ is a featherless biped} \right\}
	=
	\left\{ x \mid x \text{ is human} \right\}
\]
(let's put aside the issue of dinosaurs).

As another example, we have our empty set $\varnothing$ that contains no objects.
We can have a set that $\{1, 2, 3\}$, or maybe the set of natural numbers $\mathbb N = \{0, 1, 2, \dots \}$.  (For the purposes of set theory, $0$ is usually considered a natural number.)
Sets can even contain other sets, like $\left\{ \mathbb Z, \mathbb Q, \mathbb N \right\}$. Fine and dandy, right?

The trouble is that this definition actually isn't good enough, and here's why.
If we just say ``a set is any collection of objects'',
then we can consider a really big set $V$, the set of all sets.
So far no problem, right?
$V$ has the oddity that it has to contain itself $V \in S$,
but oh well, no big deal.

Unfortunately, this existence of this $V$ leads immediately to a paradox.
The classical one is Bertrand's Paradox.
I will instead present a somewhat simpler one:
note only does $V$ contain itself, \emph{every subset $S \subseteq V$} is itself
an element of $V$ (i.e. $S \in V$).
If we let $\PP(V)$ denote the subsets of $V$, then we have an inclusion
\[ \PP(V) \injto V. \]
This is bad, for the following reason:
\begin{lemma}[Cantor's Diagonal Argument]
	\label{lem:cantor_diag}
	For \emph{any} set $X$, it's impossible to construct a
	map $\iota : \PP(X) \injto X$.
\end{lemma}
\begin{proof}
	Assume for contradiction $\iota$ exists.
	\begin{exercise}
		Show that there exists a surjective map $j : X \to \PP(X)$.
		(This is easier than it appears, just ``invert $\iota$'').
	\end{exercise}
	We now claim that $j$ can't exist.
	The idea is contained inside the picture:
	\[
		\begin{array}{cccccccc}
			&& x_1 & x_2 & x_3 & x_4 & x_5 & \dots \\ \cline{3-8}
			x_1 & \mapsto & \mathbf0 & 1 & 1 & 0 & 1 & \dots \\
			x_2 & \mapsto & 1 & \mathbf1 & 0 & 1 & 1 & \dots \\
			x_3 & \mapsto & 0 & 1 & \mathbf0 & 0 & 1 & \dots \\
			x_4 & \mapsto & 1 & 0 & 0 & \mathbf1 & 0 & \dots \\
			x_5 & \mapsto & 0 & 1 & 1 & 1 & \mathbf1 & \dots \\
			\vdots && \vdots & \vdots & \vdots & \vdots & \vdots & \ddots
		\end{array}
	\]
	here for each $j(x) \subseteq X$, I'm writing ``$1$'' to mean that
	the element is inside $j(x)$, and ``$0$'' otherwise.\footnote{
		Technically, I don't know that $X$ is countable,
		so it's not valid to write $x_1$, $x_2$, but whatever,
		you get the idea.}
	So $j(x_1) = \{x_2, x_3, x_5 \dots\}$.

	Then we can read off the diagonal to get a new set.
	In our example, the diagonal specifies a set
	$A = \{x_2, x_4, x_5 \dots\}$.
	Then we invert it take a set $B = \{x_1, x_3, \dots\}$.
	In symbols, we consider the set
	\[ B = \left\{ x \mid x \notin j(x) \right\} \]
	By construction, $B \subseteq X$ is not in the image of $j$,
	which is a contradiction since $j$ was supposed to be injective.
\end{proof}


Now if you're not a set theorist, you could probably just brush this off,
saying ``oh well, I guess you can't look at certain sets''.
But if you're a set theorist, this worries you,
because you realize it means that you can't just define a set as ``a collection of objects'',
because then everything would blow up. Something more is necessary.



\section{The Language of Set Theory}
We need a way to refer to sets other
than the informal description of ``collection of objects''.

So here's what we're going to do.
We'll start by defining a formal \emph{language of set theory},
a way of writing logical statements.
First of all we can throw in our usual logical operators:
\begin{itemize}
	\ii $\forall$ means ``for all''
	\ii $\exists$ means ``exists''
	\ii $=$ means ``equal''
	\ii $X \implies Y$ means ``if $X$ then $Y$''
	\ii $A \land B$ means ``$A$ and $B$''
	\ii $A \lor B$ means ``$A$ or $B$''
	\ii $\neg A$ means ``not $A$''.
\end{itemize}

Since we're doing set theory,
there's only one more operator we add in: the inclusion $\in$.
And that's all we're going to use (for now).

So how do we express something like ``the set $\{1, 2\}$''?
The trick is that we're not going to actually ``construct'' any sets,
but rather refer to them indirectly, like so:
\[ \exists S : x \in S \iff \left( (x=1) \lor (x=2) \right). \]
This reads: ``there exists an $S$ such that $x$ is in $S$ if
and only if either $1$ is in $S$ or $2$ is in $S$''.
We don't have to refer to sets as objects in and of themselves anymore -- we now have a way to ``create'' our sets, by writing formulas for exactly what they contain. This is something a machine can parse.

Well, what are going to do with things like $1$ and $2$, which are not sets? 
Answer:
\begin{moral}
	Elements of sets are themselves sets.
\end{moral}
We're going to make \textbf{everything} into a set. Natural numbers will be sets. Ordered pairs will be sets. Functions will be sets. 
Later, I'll tell you exactly how we manage to do something like encode $1$ as a set. For now, all you need to know is that that sets don't just hold objects; they hold other sets.

So now it makes sense to talk about whether something is a set or not: $\exists x$ means ``$x$ is a set'', while $\nexists x$ means ``$x$ is not a set''.
In other words, we've rephrased the problem of deciding whether something is a set to whether it exists, which makes it easier to deal with in our formal language.
That means that our axiom system had better find some way to let us show a lot of things exist, without letting us prove the following formula:
\[ \exists S \forall x : x \in S. \]
For if we prove this formula, then we have our ``bad'' set from that caused us to go down the rabbit hole in the first place.


\section{The Axioms of $\ZFC$}
I don't especially want to get into details about these axioms;
if you're interested, read:
\begin{itemize}
	\ii \footnotesize \url{https://usamo.wordpress.com/2014/11/13/set-theory-an-intro-to-zfc-part-1/}
	\ii \footnotesize \url{https://usamo.wordpress.com/2014/11/18/set-theory-part-2-constructing-the-ordinals/}
\end{itemize}
Here is a much terser description of the axioms,
which also includes the corresponding sentence in the language of set theory.
It is worth the time to get some practice parsing $\forall$, $\exists$, etc.\
and you can do so by comparing the formal sentences with the natural statement of the axiom.

First, the two easiest axioms:
\begin{itemize}
	\ii $\Extensionality$ is the sentence
	$\forall x \forall y
	\left( \left( \forall a  \left( a \in x \iff a \in y \right) \right)
	\implies x = y \right)$,
	which says that if two sets $x$ and $y$ have the same elements,
	then $x = y$.

	\ii $\EmptySet$ is the sentence $\exists a : \forall x \; \neg (x \in a)$;
	it says there exists a set with no elements.
	By $\Extensionality$ this set is unique, so we denote it $\varnothing$.
\end{itemize}

The next two axioms give us basic ways of building new sets.
\begin{itemize}
	\ii Given two elements $x$ and $y$, there exists a set $a$ containing only those two elements.
	In machine code, this is the sentence $\Pairing$, written
	\[ \forall x \forall y \exists a \quad \forall z,
		\; z \in a \iff \left( (z=x) \lor (z=y) \right). \]
	By $\Extensionality$ this set $a$ is unique, so we write $a = \{x,y\}$.

	\ii Given a set $a$, we can create the union of the elements of $a$.
	For example, if $a = \{ \{1,2\}, \{3,4\} \}$, then $z = \{1,2,3,4\}$ is a set.
	Formally, this is the sentence $\Union$:
	\[ \forall a \exists U \quad \forall x \; (x \in U) \iff (\exists y : x \in y \in U). \]
	Since $U$ is unique by $\Extensionality$, we denote it $\cup a$.

	\ii 
	We can construct the \vocab{power set} $\mathcal P(x)$.
	Formally, the sentence $\PowerSet$ says that
	\[ \forall x \exists P \forall y (y \in P \iff y \subseteq x) \]
	where $y \subseteq x$ is short for $\forall z (z \in y \implies z \in x)$.
	As $\Extensionality$ gives us uniqueness of $P$,
	we denote it $\mathcal P(x)$.

	\ii $\Foundation$ says there are no infinite descending chains
	\[ x_0 \ni x_1 \ni x_2 \ni \dots. \]
	This is important, because it lets us induct.
	In particular, \textbf{no set contains itself}.

	\ii $\Infinity$ implies that $\omega = \{0,1,\dots\}$ is a set.
\end{itemize}
These are all things you are already used to, so keep your intuition there.
The next one is less intuitive:
\begin{itemize}
	\ii The \vocab{schema of restricted comprehension} says the following.
	If we are \emph{given a set $X$}, and some formula $\phi$
	(for example $\phi(x)$ might be ``$x$ is not the empty set, i.e. $\exists a(a\in x)$'')
	then we can \emph{filter} through the elements of $X$ to get a subset
	\[ Y = \left\{ x \in X \mid \phi(x) \right\}. \]
	Formally, given a formula $\phi$:
	\[
		\forall X \quad \exists Y \quad
		\forall y (y \in Y \iff y \in X \land \phi(y)).
	\]
\end{itemize}
Notice that we may \emph{only} do this filtering over an already given set.
So it is not valid to create
$ \left\{ x \mid x \text{ is a set} \right\} $.
We are thankful for this, because this lets us evade Cantor's paradox.

\begin{abuse}
	Note that technically, there are infinitely many sentences,
	a $\Comprehension_\phi$ for every possible formula $\phi$.
	By abuse of notation, we let $\Comprehension$ abbreviate
	the infinitely many axioms $\Comprehension_\phi$ for every $\phi$.
\end{abuse}

There is one last schema called $\Replacement_\phi$.
Suppose $X$ is a set and $\phi(x,y)$ is some formula
such that for every $x \in X$, there is a \emph{unique} $y$ in the universe
such that $\phi(x,y)$ is true: for example ``$y = x \cup \{x\}$'' works.
(In effect, $\phi$ is defining a function $f$ on $X$.)
Then there exists a set $Y$ consisting exactly of these images:
(i.e. $f``X$ is a set).
\begin{abuse}
	By abuse of notation, we let $\Replacement$ abbreviate
	the infinitely many axioms $\Replacement_\phi$ for every $\phi$.
\end{abuse}

We postpone discussion of the Axiom of Choice momentarily.

\section{Encoding}
Now that we have this rickety universe of sets, we can start re-building math.
You'll get to see this more in the next chapter on ordinal numbers.

\begin{definition}
	An \vocab{ordered pair} $(x,y)$
	is a set of the form
	\[ (x,y) \defeq 
		\left\{ \left\{ x \right\}, \left\{ x,y \right\} \right\}. \]
\end{definition}
Note that $(x,y) = (a,b)$ if and only if $x=a$ and $y=b$.
Ordered $k$-tuples can be defined recursively: a three-tuple $(a,b,c)$ means $(a,(b,c))$.

\begin{definition}
	A \vocab{function} $f : X \to Y$ 
	consists is defined as a collection of ordered pairs
	with the following properties:
	\begin{itemize}
		\ii If $(x,y) \in f$, then $x \in X$ and $y \in Y$.
		\ii For every $x \in X$, there is a unique $y \in Y$
		such that $(x,y) \in f$. We denote this $y$ by $f(x)$.
	\end{itemize}
\end{definition}

\begin{definition}
	The \vocab{natural numbers} are defined inductively as
	\begin{align*}
		0 &= \varnothing \\
		1 &= \{0\} \\
		2 &= \{0,1\} \\
		3 &= \{0,1,2\} \\
		&\vdotswithin=
	\end{align*}
	The set of all natural numbers is denoted $\omega$.
\end{definition}
\begin{abuse}
	Yes, I'm sorry, in set theory $0$ is considered a natural number.
	For this reason I'm using $\omega$ and not $\NN$
	since I explicitly have $0\notin\NN$ in all other parts of this book.
\end{abuse}

Et cetera, et cetera.

\section{Choice and Well-Ordering}
The Axiom of Choice states that given a collection $Y$ of nonempty sets,
there is a function $g : Y \to \cup Y$ which ``picks'' an element of each member of $Y$.
That means $g(y) \in y$ for every $y \in Y$.
(The typical illustration is that $Y$ contains infinitely many drawers,
and each drawer (a $y$) has some sock in it.)

Formally, it is the sentence
\[ \forall Y \left(\varnothing \notin Y
	\implies 
	\exists g : Y \to \cup Y
	\text{ such that }
	\forall y \in Y \left( g(y) \in y \right).
	\right)
\]
The tricky part is not that we can conceive of such a function $g$,
but that in fact this function $g$ is \emph{actually a set}.

There is an equivalent formulation which is often useful.
\begin{definition}
	A \vocab{well-ordering} $<$ of $X$ is a strict, total order on $X$
	which has no infinite descending chains.
\end{definition}
Well-orderings on a set are very nice, because we can pick minimal elements:
this lets us do induction, for example.
\begin{example}[Examples and Non-Examples of Well-Orderings]
	\listhack
	\begin{enumerate}[(a)]
		\ii The natural numbers $\omega = \{0,1,2,\dots\}$
		are well-ordered by $<$.
		\ii The integers $\ZZ = \{\dots,-2,-1,0,1,2,\dots\}$ are not well-ordered by $<$,
		because there are infinite descending chains (take $-1 > -2 > -3 > \dots$).
		\ii The positive real numbers are not well-ordered by $<$,
		again because of the descending chain $\frac11>\frac12>\frac13>\dots$.
		\ii The positive integers are not well-ordered by the divisibility operation $\mid$.
		While there are no descending chains, there are elements which cannot be compared
		(for example $3 \nmid 5$, $5 \nmid 3$ and $3 \neq 5$).
	\end{enumerate}
\end{example}

\begin{theorem}
	[Well-Ordering Theorem]
	Assuming Choice, for every set we can place some well-ordering on it.
\end{theorem}
In fact, the Well-Ordering Theorem is actually equivalent to the Axiom of Choice.

\section{Sets vs Classes}
\prototype{The set of all sets is the standard example of a proper class.}
We close the discussion of $\ZFC$ by mentioning ``classes''.

Roughly, the ``bad thing'' that happened was that we considered a set $S$, the
``set of all sets'', and it was \emph{too big}.
That is,
\[ \left\{ x \mid x \text{ is a set} \right\} \]
is not good.
Similarly, we cannot construct a set
\[ \left\{ x \mid x \text{ is an ordered pair} \right\}. \]
The lesson of Cantor's Paradox is that we cannot create any sets we want;
we have to be more careful than that.

Nonetheless, if we are given a set
we can still tell whether or not it is an ordered pair.
So for convenience, we will define a \vocab{class} to be
a ``concept'' like the ``class of all ordered pairs''.
Formally, a class is defined by some formula $\phi$:
it consists of the sets which satisfy the formula.

In particular:
\begin{definition}
	The class of all sets is denoted $V$, defined by $V = \left\{ x \mid x=x \right\}$.
	It is called the \vocab{von Neumann universe}.
\end{definition}

A class is a \vocab{proper class} if it is not a set,
so for example we have:
\begin{theorem}[There is no set of all sets]
	$V$ is a proper class.
\end{theorem}
\begin{proof}
	Assume not, and $V$ is a set. Then $V \in V$,
	which violates $\Foundation$.
\end{proof}

\begin{abuse}
	Given a class $C$, we will write $x \in C$ to mean
	that $x$ has the defining property of $C$.
	For example, $x \in V$ means ``$x$ is a set''.

	It does not mean $x$ is an element of $V$
	-- this doesn't make sense as $V$ is not a set.
\end{abuse}

\section\problemhead
\begin{problem}
	Let $A$ and $B$ be sets.
	Show that $A \cap B$ and $A \times B$ are sets.
\end{problem}

\begin{problem}
	Show that the class of all groups is a proper class.
	(You can take the definition of a group as a pair $(G, \cdot)$
	where $\cdot$ is a function $G \times G \to G$.)
\end{problem}
\begin{problem}
	Show that the Axiom of Choice follows from the Well-Ordering Theorem.
\end{problem}

\begin{dproblem}
	Prove that actually, $\Replacement \implies \Comprehension$.
\end{dproblem}

\begin{problem}
	[From Taiwan IMO Training Camp]
	Consider infinitely many people each wearing a hat,
	which is either red, green, or blue.
	Each person can see the hat color of everyone except themselves.
	Simultaneously each person guesses the color of their hat.
	Show that they can form a strategy such that at most finitely many people guess their color incorrectly. 
\end{problem}

\chapter{Ordinals}
\section{Counting for Preschoolers}
In preschoolers, we were told to count as follows.
We defined a set of symbols $1$, $2$, $3$, $4$, \dots.
Then the teacher would hold up three apples and say:
\begin{quote}
	``One . . . two . . . three!  There are three apples.''
\end{quote}

\missingfigure{three apples}

The implicit definition is that the \emph{last} number said is the final answer.
This raises some obvious problems if we try to count to infinite sets, but even in the finite
world, this method of counting fails for the simplest set of all:
how many apples are in the following picture?

\missingfigure{zero apples (velociraptor)}

Answer: $0$. There is nothing to say, and our method of counting has failed
for the simplest set of all: the empty set.

\section{Counting for Set Theorists}
\prototype{$\omega+1 = \{0,1,2,\dots,\omega\}$ might work.}
Rather than using the \emph{last} number listed, I propose the following:
we start with a list of symbols $0$, $1$, $2$, \dots\ and our final answer
is going to be the \emph{first} number which was \emph{not} said.
Thus to count three apples, we would say 
\begin{quote}
	``Zero . . . one . . . two!  There are three apples.''
\end{quote}
We will call these numbers \emph{ordinal numbers} (rigorous definition later).
In particular, we'll \emph{define} each ordinal to be the set of things we say:
\begin{align*}
	0 &= \varnothing \\
	1 &= \{0\} \\
	2 &= \{0,1\} \\
	3 &= \{0,1,2\} \\
	&\vdotswithin=
\end{align*}
In this way we can write out the natural numbers.
You can have some fun with this, by saying things like
\[
	4 \defeq
	\left\{ 
		\left\{  \right\},
		\left\{ \left\{  \right\} \right\},
		\left\{ \left\{  \right\}, \left\{ \left\{  \right\} \right\} \right\},
		\left\{ 
			\left\{  \right\},
			\left\{ \left\{  \right\} \right\},
			\left\{ \left\{  \right\}, \left\{ \left\{  \right\} \right\} \right\}
		\right\}
	\right\}
\]
In this way, we soon write down all the natural numbers.
The next ordinal, $\omega$,\footnote{
	That $\omega$ is actually a set is not obvious.
	The proof follows from the actual statement of $\Infinity$,
	which I've dutifully omitted.
	In fact, $\Infinity$ is equivalent to the existence of $\omega$.
} is defined as
\begin{align*}
	\omega &= \left\{ 0, 1, 2, \dots \right\} \\
	\intertext{Then comes}
	\omega+1 &= \left\{ 0, 1, 2, \dots, \omega \right\} \\
	\omega+2 &= \left\{ 0, 1, 2, \dots, \omega, \omega+1 \right\} \\
	\omega+3 &= \left\{ 0, 1, 2, \dots, \omega, \omega+1, \omega+2 \right\} \\
	&\vdotswithin= \\
	\intertext{And in this way we define $\omega+n$, and eventually reach}
	\omega \cdot 2 = \omega+\omega &= \left\{ 0, 1, 2 \dots, \omega, \omega+1, \omega+2, \dots \right\} \\
	\omega \cdot 2 + 1 &= \left\{ 0, 1, 2 \dots, \omega, \omega+1, \omega+2, \dots, \omega \cdot 2 \right\}.
\end{align*}
In this way we obtain
\begin{align*}
	0,\; & 1,\; 2,\; 3,\; \dots,\; \omega \\
	& \omega+1,\; \omega+2,\; \dots,\; \omega+\omega \\
	& \omega \cdot 2 +1,\; \omega \cdot 2 +2,\; \dots,\; \omega \cdot 3,\; \\
	& \vdots \\
	& \omega^2 + 1,\; \omega^2+2,\; \dots \\
	& \vdots \\
	& \omega^3,\; \dots,\; \omega^4,\; \dots,\; \omega^\omega \\
	& \vdots \\
	& \omega^{\omega^{\omega^{\dots}}} \\
\end{align*}

\missingfigure{Spiral of ordinals}

\begin{remark}
	(Digression)
	The number $\omega^{\omega^{\omega^{\dots}}}$ has a name, $\eps_0$;
	it has the property that $\omega^{\eps_0} = \omega$.
	The reason for using ``$\eps$'' (which is usually used to denote small quantities)
	is that, despite how huge it may appear, it is actually a countable set.
	More on that later.
\end{remark}

\section{Definition of an Ordinal}
Our informal description of ordinals gives us a chain
\[ 0 \in 1 \in 2 \in \dots \in \omega \in \omega+1 \in \dots. \]
To give the actual definition of an ordinal, I need to define two auxiliary terms first.
\begin{definition}
	A set $x$ is \vocab{transitive} if whenever $z \in y \in x$, we have $z \in x$ also.
\end{definition}
\begin{example}
	[$7$ is Transitive]
	The set $7$ is transitive: for example, $2 \in 5 \in 7 \implies 2 \in 7$.
\end{example}
\begin{ques}
	Show that this is equivalent to: whenever $y \in x$, $y \subseteq x$.
\end{ques}
Moreover, recall the definition of ``well-ordering'': a strict linear order
with no infinite descending chains.
\begin{example}
	[$\in$ is a well-ordering on $\omega \cdot 3$]
	In $\omega \cdot 3$, we have an ordering
	\[ 0 \in 1 \in 2 \in \dots \in \omega \in \omega+1 \in \dots
		\in \omega \cdot 2 \in \omega \cdot 2 + 1 \in \dots. \]
	which has no infinite descending chains.
	Indeed, a typical descending chain might look like
	\[ \omega \cdot 2 + 6 \ni \omega \cdot 2 \ni
		\omega + 2015 \ni \omega+3 \ni \omega \ni 1000 \ni 256 \ni 42 \ni 7 \ni 0. \]
	Even though there are infinitely many elements, there is no way
	to make an infinite descending chain.
\end{example}
\begin{exercise}
	(Important) Convince yourself there are no infinite descending chains of ordinals at all
	(which must be true by $\Foundation$!).
\end{exercise}

\begin{definition}
	An \vocab{ordinal} is a transitive set which is well-ordered by $\in$.
	The class of all ordinals is denoted $\On$.
\end{definition}

\begin{ques}
	Satisfy yourself that this definition works.
\end{ques}

We typically use Greek letters $\alpha$, $\beta$, etc.\ for ordinal numbers.
\begin{definition}
	We write
	\begin{itemize}
		\ii $\alpha < \beta$ to mean $\alpha \in \beta$,
		and $\alpha > \beta$ to mean $\alpha \ni \beta$.
		\ii $\alpha \le \beta$ to mean $\alpha \in \beta$ or $\alpha = \beta$,
		and $\alpha \ge \beta$ to mean $\alpha \ni \beta$ or $\alpha = \beta$,
	\end{itemize}
\end{definition}

\begin{theorem}[Ordinals are Strictly Ordered]
	Given any two ordinal numbers $\alpha$ and $\beta$,
	either $\alpha < \beta$, $\alpha = \beta$ or $\alpha > \beta$.
\end{theorem}
\begin{proof}
	Surprisingly annoying, thus omitted.
\end{proof}
\begin{theorem}[Ordinals Represent All Order Types]
	Suppose $<$ is a well-ordering on a set $X$.
	Then there exists a unique ordinal $\alpha$
	such that there is a bijection $\alpha \to X$
	which is order preserving.
\end{theorem}
Thus ordinals represent the possible \emph{equivalence classes} of order types.
Any time you hale a well-ordered set, it is isomorphic to a unique ordinal.

We now formalize the ``$+1$'' operation we were doing:
\begin{definition}
	Given an ordinal $\alpha$, we let $\alpha+1 = \alpha \cup \{\alpha\}$.
	An ordinal of the form $\alpha+1$ is called a \vocab{successor ordinal}.
\end{definition}
\begin{definition}
	If $\lambda$ is an ordinal which is neither zero nor a successor ordinal,
	then we say $\lambda$ is a \vocab{limit ordinal}.
\end{definition}
\begin{example}
	[Sucessor and Limit Ordinals]
	$7$, $\omega+3$, $\omega\cdot2+2015$ are successor ordinals,
	but $\omega$ and $\omega \cdot 2$ are limit ordinals.
\end{example}

\section{Ordinals Are ``Tall''}
First, we note that:
\begin{theorem}
	[There is no set of all ordinals]
	$\On$ is a proper class.
\end{theorem}
\begin{proof}
	Assume for contradiction not.
	Then $\On$ is well-ordered by $\in$ and transitive, so $\On$ is an ordinal,
	i.e.\ $\On \in \On$, which violates $\Foundation$.
\end{proof}

From this we deduce:
\begin{theorem}
	[Sets of Ordinals Are Bounded]
	Let $A \subseteq \On$.
	Then there is some ordinal $\alpha$ such that $A \in \alpha$
	(i.e.\ $A$ must be bounded).
\end{theorem}
\begin{proof}
	Otherwise, look at $\cup A$.
	It is a set.
	But if $A$ is unbounded it must equal $\On$,
	which is a contradiction.
\end{proof}
In light of this, every set of ordinals has a \vocab{supremum},
which is the least upper bound. We denote this by $\sup A$.

\begin{ques}
	Show that
	\begin{enumerate}[(a)]
		\ii $\sup (\alpha+1) = \alpha$ for any ordinal $\alpha$.
		\ii $\sup \lambda = \lambda$ for any limit ordinal $\lambda$.
	\end{enumerate}
\end{ques}

The pictorial ``tall'' will be explained in a few sections.

\section{Transfinite Induction and Recursion}
The fact that $\in$ has no infinite descending chains means that induction and recursion still work verbatim.
\begin{theorem}[Transfinite Induction]
	Given a statement $P(-)$, suppose that
	\begin{itemize}
		\ii $P(0)$ is true, and
		\ii If $P(\alpha)$ is true for all $\alpha < \beta$, then $P(\beta)$ is true.
	\end{itemize}
	Then $P(\alpha)$ is true for every ordinal $\alpha$.
\end{theorem}
\begin{theorem}
	[Transfinite Recursion]
	To define a sequence $x_\alpha$ for every ordinal $\alpha$,
	it suffices to
	\begin{itemize}
		\ii define $x_0$, then
		\ii for any $\beta$, define $x_\beta$ for any $\alpha < \beta$.
	\end{itemize}
\end{theorem}

The difference between this and normal induction lies in the \emph{limit ordinals}.
In real life, we might only do things like ``define $x_{n+1} = \dots$''.
But this is not enough to define $x_\alpha$ for all $\alpha$,
because we can't hit $\omega$ this way.
Similarly, the simple $+1$ doesn't let us hit the ordinal $2\omega$,
even if we already have $\omega+n$ for all $n$.
In other words, simply incrementing by $1$ cannot get us past limit stages,
but using transfinite induction to jump upwards lets us sidestep this issue.

So a transfinite induction or recursion is very often broken up into three cases.
In the induction phrasing, it looks like
\begin{itemize}
	\ii (Zero Case) First, resolve $P(0)$.
	\ii (Successor Case) Show that from $P(\alpha)$ we can get $P(\alpha+1)$.
	\ii (Limit Case) For $\lambda$ a limit ordinal,
	show that $P(\lambda)$ holds given $P(\alpha)$ for all $\alpha < \lambda$,
	where $\lambda$ is a limit ordinal.
\end{itemize}
Similarly, transfinite recursion often is split into cases too.
\begin{itemize}
	\ii (Zero Case) First, define $x_0$.
	\ii (Successor Case) Define $x_{\alpha+1}$ from $x_\alpha$.
	\ii (Limit Case) Define $x_\lambda$ from $x_\alpha$ for all $\alpha < \lambda$,
	where $\lambda$ is a limit ordinal.
\end{itemize}
In both situations, finite induction only does the first two cases,
but if we're able to do the third case we can climb above the barrier $\omega$.

\section{Ordinal Arithmetic}
\prototype{$1+\omega=\omega \neq \omega+1$.}
To give an example of transfinite recursion, let's define addition of ordinals.
Recall that we defined $\alpha+1 = \alpha \cup \{\alpha\}$.
By transfinite recursion, let
\begin{align*}
	\alpha + 0 &= \alpha \\
	\alpha + (\beta + 1) &= (\alpha + \beta) + 1 \\
	\alpha + \lambda &= \bigcup_{\beta < \lambda} (\alpha + \beta).
\end{align*}
Here $\lambda \neq 0$.

We can also do this explicitly:
The picture is to just line up $\alpha$ after $\beta$.
That is, we can consider the set
\[
	X = 
	\left( \left\{ 0 \right\} \times \alpha \right)
	\cup
	\left( \left\{ 1 \right\} \times \beta \right)
\]
(i.e.\ we tag each element of $\alpha$ with a $0$, and
each element of $\beta$ with a $1$).
We then impose a well-ordering on $X$ by a lexicographic ordering $\llex$
(sort by first component, then by second).
This well-ordering is isomorphic to a unique ordinal, 
\begin{example}
	[$2+3=5$]
	Under the explicit construction for $\alpha = 2$ and $\beta = 3$, we get the set
	\[
		X = \left\{ (0,0) < (0,1) < (1,0) < (1,1) < (1,2) \right\}
	\]
	which is isomorphic to $5$.
\end{example}

\begin{example}[Ordinal Arithmetic is Not Commutative]
	Note that $1 + \omega = \omega$!
	Indeed, under the transfinite definition, we have
	\[ 1 + \omega = \cup_n (1+n) = 2 \cup 3 \cup 4 \cup \dots = \omega. \]
	With the explicit construction, we have
	\[ X = \left\{ (0,0) < (1,0) < (1,1) < (1,2) < \dots \right\} \]
	which is isomorphic to $\omega$.
\end{example}
\begin{exercise}
	Show that $n+\omega = \omega$ for any $n \in \omega$.
\end{exercise}

\begin{remark}
	Ordinal addition is not commutative.
	However, from the explicit construction
	we can see that it is at least associative.
\end{remark}

Similarly, we can define multiplication in two ways.
By transfinite induction:
\begin{align*}
	\alpha \cdot 0 &= \alpha \\
	\alpha \cdot (\beta + 1) &= (\alpha \cdot \beta) + \alpha \\
	\alpha \cdot \lambda &= \bigcup_{\beta < \lambda} \alpha \cdot \beta.
\end{align*}
We can also do an explicit construction: $\alpha \cdot \beta$
is the order type of
\[ \llex \text{ applied to } \beta \times \alpha. \]
\begin{example}[Ordinal Multiplication is Not Commutative]
	We have $\omega \cdot 2 = \omega + \omega$,
	but $2 \cdot \omega = \omega$.
\end{example}
\begin{exercise}
	Prove this.
\end{exercise}
\begin{exercise}
	Verify that ordinal multiplication
	(like addition) is associative but not commutative.
	(Look at $\gamma \times \beta \times \alpha$.)
\end{exercise}

Exponentiation can also be so defined, though the explicit construction is less natural.
\begin{align*}
	\alpha^0 &= 1 \\
	\alpha^{\beta+1} &= \alpha^{\beta} \cdot \alpha \\
	\alpha^{\lambda} &= \bigcup_{\beta < \lambda} \alpha^\beta.
\end{align*}
\begin{exercise}
	Verify that $2^\omega = \omega$.
\end{exercise}


\section{The Hierarchy of Sets}
We now define the \vocab{von Neumann Hierarchy} by transfinite recursion.
\begin{definition}
	By transfinite induction, we set
	\begin{align*}
		V_0 &= \varnothing \\
		V_{\alpha + 1} &= \PP(V_\alpha) \\
		V_\lambda &= \bigcup_{\alpha<\lambda} V_\alpha
	\end{align*}
\end{definition}
By transfinite induction, we see $V_\alpha$ is transitive
and that $V_\alpha \subseteq V_\beta$ for all $\alpha < \beta$.

\begin{example}[$V_\alpha$ for $\alpha \le 3$]
	The first few levels of the hierarchy are:
	\begin{align*}
		V_0 &= \varnothing \\
		V_1 &= \left\{ 0 \right\} \\
		V_2 &=  \left\{ 0, 1 \right\} \\
		V_3 &= \left\{ 0, 1, 2, \left\{ 1 \right\} \right\}.
	\end{align*}
	Notice that for each $n$, $V_n$ consists of only finite sets,
	and each $n$ appears in $V_{n+1}$ for the first time.
	Observe that
	\[ V_\omega = \bigcup_{n \in \omega} V_n \]
	consists only of finite sets; thus $\omega$ appears for the first time
	in $V_{\omega+1}$.
\end{example}
\begin{ques}
	How many sets are in $V_5$?
\end{ques}

\begin{definition}
	The \vocab{rank} of a set $y$, denoted $\rank(y)$,
	is the smallest ordinal $\alpha$ such that $y \in V_{\alpha+1}$.
\end{definition}
\begin{example}
	$\rank(2) = 2$, and actually $\rank(\alpha)=\alpha$
	for any ordinal $\alpha$ (problem later).
	This is the reason for the extra ``$+1$''.
\end{example}
\begin{ques}
	Show that $\rank(y)$ is the smallest ordinal $\alpha$
	such that $y \subseteq V_\alpha$.
\end{ques}

It's not yet clear that the rank of a set actually exists, so we prove:
\begin{theorem}[The von Neumann Hierachy is Complete]
	The class $V$ is equal to $\bigcup_{\alpha \in \On} V_\alpha$.
	In other words, every set appears in some $V_\alpha$.
\end{theorem}
\begin{proof}
	Assume for contradiction this is false.
	The key is that because $\in$ is well-founded,
	we can take a $\in$-minimal counterexample $x$.
	Thus $\rank(y)$ is defined for every $y \in x$,
	and we can consider (by $\Replacement$) the set
	\[ \left\{ \rank(y) \mid y \in x \right\}. \]
	Since it is a set of ordinals, it is bounded.
	So there is some large ordinal $\alpha$ such that $y \in V_\alpha$
	for all $y \in x$, i.e.\ $x \subseteq V_\alpha$,
	so $x \in V_{\alpha+1}$.
\end{proof}

This leads us to the following picture of the universe $V$.
We can image the universe $V$ as a triangle, built in several stages or layers,
$V_0 \subset V_1 \subset V_2 \subset \dots$.
This universe doesn't have a top: but each of the $V_i$ do.
However, the universe has a very clear bottom.
Each stage is substantially wider than the previous one.

In the center of this universe are the ordinals:
for every successor $V_\alpha$, exactly one new ordinal appears, namely $\alpha$.
Thus we can picture the class of ordinals as a thin line
that stretches the entire height of the universe.
A set has rank $\alpha$ if it appears at the same stage that $\alpha$ does.

\begin{center}
	\begin{asy}
		size(11cm);
		pair A = (12,30);
		pair B = -conj(A);
		pair M = midpoint(A--B);
		pair O = origin;
		MP("V", A, dir(10));
		draw(A--O--B);

		fill(A--O--B--cycle, opacity(0.3)+palecyan);

		MP("V_0 = \varnothing", origin, dir(-20));
		MP("V_1 = \{\varnothing\}", 0.05*A, dir(0));
		MP("V_2 = \{\varnothing, \{\varnothing\} \}", 0.10*A, dir(0));

		draw(MP("V_n", 0.3*A, dir(0))--0.3*B);
		draw(MP("V_{n+1} = \mathcal P(V_n)", 0.35*A, dir(0))--0.35*B);
		Drawing("n", 0.35*M, dir(45));

		draw(MP("V_\omega = \bigcup V_n", 0.5*A, dir(0))--0.5*B);
		draw(MP("V_{\omega+1} = \mathcal P(V_{\omega})", 0.55*A, dir(0))--0.55*B);
		Drawing("\omega", 0.55*M, dir(45));
		draw(MP("V_{\omega+2} = \mathcal P(V_{\omega+1})", 0.6*A, dir(0))--0.6*B);
		Drawing("\omega+1", 0.6*M, dir(45));

		draw(MP("V_{\omega+\omega}", 0.8*A, dir(0))--0.8*B);

		draw(origin--M);
		MP("\mathrm{On}", M, dir(90));

	\end{asy}
\end{center}

All of number theory, the study of the integers, lives inside $V_\omega$.
Real analysis, the study of real numbers, lives inside $V_{\omega+1}$, since a real number
can be encoded as a subset of $\NN$ (by binary expansion).
Functional analysis lives one step past that, $V_{\omega+2}$.
For all intents and purposes, most mathematics does not go beyond $V_{\omega+\omega}$.
This pales in comparison to the true magnitude of the whole universe.

\section\problemhead
\begin{problem}
	Prove that $\rank(\alpha) = \alpha$ for any $\alpha$
	by transfinite induction.
\end{problem}

\begin{problem}
	[Online Math Open]
	Count the number of transitive sets in $V_5$.
\end{problem}

\begin{problem}
	[Brazilian Olympic Revenge]
	Let $a_2$ be any positive integer.
	We define the infinite sequence $a_2$, $a_3$, \dots recursively as follows.
	If $a_{n} = 0$, then $a_{n+1} = 0$.
	Otherwise, we write $a_{n+1}$ in base $n$, then write all exponents in base $n$, and so on until all
	numbers in the expression are at most $n$.
	Then we replace all instances of $n$ by $n+1$ (including the exponents!), subtract $1$,
	and set the result to $a_{n+1}$.
	For example, if $a_2 = 11$ we have
		\begin{align*}
			a_2 &= 2^{3} + 2 + 1 = 2^{2+1} + 2 + 1 \\
			a_3 &= 3^{3+1}+3+1-1 = 3^{3+1} + 3\\
			a_4 &= 4^{4+1} + 4 - 1 = 4^{4+1} + 3 \\
			a_5 &= 5^{5+1} + 3 - 1 = 5^{5+1} + 2
		\end{align*}
	and so on. Prove that $a_N = 0$ for some integer $N > 2$.
\end{problem}

\chapter{Cardinals}
An ordinal measures a total ordering.
However, it does not do a fantastic job at measuring size.
For example, there is a bijection between the elements of $\omega$ and $\omega+1$:
\[
	\begin{array}{rccccccc}
		\omega+1 = & \{ & \omega & 0 & 1 & 2 & \dots & \} \\
		\omega = & \{ & 0 & 1 & 2 & 3 & \dots & \}.
	\end{array}
\]
In fact, as you likely already know,
there is even a bijection between $\omega$ and $\omega^2$:
\[
	\begin{array}{l|cccccc}
		+ & 0 & 1 & 2 & 3 & 4 & \dots \\ \hline
		0 & 0 & 1 & 3 & 6 & 10 & \dots \\
		\omega & 2 & 4 & 7 & 11 & \dots & \\
		\omega \cdot 2 & 5 & 8 & 12 & \dots & & \\
		\omega \cdot 3 & 9 & 13 & \dots & & & \\
		\omega \cdot 4 & 14 & \dots & & & &
	\end{array}
\]
So ordinals do not do a good job of keeping track of size.
For this, we turn to the notion of a cardinal number.

\section{Equinumerous sets and Cardinals}
\begin{definition}
	Two sets $A$ and $B$ are \vocab{equinumerous}, written $A \approx B$,
	if there is a bijection between them.
\end{definition}

\begin{definition}
	A \vocab{cardinal} is an ordinal $\kappa$ such that
	for no $\alpha < \kappa$ do we have $\alpha \approx \kappa$.
\end{definition}
\begin{example}[Examples of Cardinals]
	Every finite number is a cardinal.
	Moreover, $\omega$ is a cardinal.
	However, $\omega+1$, $\omega^2$, $\omega^{2015}$ are not,
	because they are countable.
\end{example}
\begin{example}[$\omega^\omega$ is Countable]
	Even $\omega^\omega$ is not a cardinal,
	since it is a countable union
	\[ \omega^\omega = \bigcup_n \omega^n \]
	and each $\omega^n$ is countable.
\end{example}
\begin{ques}
	Why must an infinite cardinal be a limit ordinal?
\end{ques}

\begin{remark}
	There is something fishy about the definition of a cardinal:
	it relies on an \emph{external} function $f$.
	That is, to verify $\kappa$ is a cardinal I can't just look at $\kappa$ itself;
	I need to examine the entire universe $V$ to make sure
	there does not exist a bijection $f : \kappa \to \alpha$ for $\alpha < \kappa$.
	For now this is no issue, but later in model theory
	this will lead to some highly counterintuitive behavior.
\end{remark}

\section{Cardinalities}
Now that we have defined a cardinal, we can discuss the size
of a set by linking it to a cardinal.

\begin{definition}
	The \vocab{cardinality} of a set $X$
	is the \emph{least} ordinal $\kappa$ such that $X \approx \kappa$.
	We denote it by $\left\lvert X \right\rvert$.
\end{definition}
\begin{ques}
	Why must $\left\lvert X \right\rvert$ be a cardinal?
\end{ques}
\begin{remark}
	One needs the Well-Ordering Theorem (equivalently, Choice)
	in order to establish that such an ordinal $\kappa$ actually exists.
\end{remark}
Since cardinals are ordinals, it makes sense to ask whether $\kappa_1 \le \kappa_2$,
and so on.
Our usual intuition works well here.
\begin{proposition}[Restatement of Cardinality Properties]
	Let $X$ and $Y$ be sets.
	\begin{enumerate}[(i)]
		\ii $X \approx Y$ if and only $\left\lvert X \right\rvert = \left\lvert Y \right\rvert$,
		if and only if there is a bijection between $X$ and $Y$.
		\ii $\left\lvert X \right\rvert \le \left\lvert Y \right\rvert$
		if and only if there is an injective map $X \injto Y$.
	\end{enumerate}
\end{proposition}
\begin{ques}
	Prove this.
\end{ques}

\section{Aleph numbers}
\prototype{$\aleph_0$ is $\omega$, and $\aleph_1$ is the first uncountable}
First, let us check that cardinals can get arbitrarily large:
\begin{proposition}
	We have $\left\lvert X \right\rvert < \left\lvert \PP(X) \right\rvert$ for every set $X$.
\end{proposition}
\begin{proof}
	There is an injective map $X \injto \PP(X)$
	but there is no injective map $\PP(X) \injto X$ by \Cref{lem:cantor_diag}.
\end{proof}

Thus we can define:
\begin{definition}
	For a cardinal $\kappa$, we define $\kappa^+$ to be the least cardinal above $\kappa$,
	called the \vocab{successor cardinal}.
\end{definition}
This $\kappa^+$ exists and has $\kappa^+ \le \left\lvert \PP(\kappa) \right\rvert$.

Next, we claim that:
\begin{exercise}
	Show that if $A$ is a set of cardinals, then $\cup A$ is a cardinal.
\end{exercise}

Thus by transfinite induction we obtain that:
\begin{definition}
	For any $\alpha \in \On$, we define the \vocab{aleph numbers} as
	\begin{align*}
		\aleph_0 &= \omega \\
		\aleph_{\alpha+1} &= \left( \aleph_\alpha \right)^+ \\
		\aleph_{\lambda} &= \bigcup_{\alpha < \lambda} \aleph_\alpha.
	\end{align*}
\end{definition}

Thus we have the following sequence of cardinals:
\[
	0 < 1 < 2 < \dots < \aleph_0 < \aleph_1 < \dots < \aleph_\omega < \aleph_{\omega+1} < \dots
\]
By definition, $\aleph_0$ is the cardinality of the natural numbers,
$\aleph_1$ is the first uncountable ordinal, \dots.

We claim the aleph numbers constitute all the cardinals:
\begin{lemma}[Aleph Numbers Constitute All Infinite Cardinals]
	If $\kappa$ is a cardinal then
	either $\kappa$ is finite (i.e.\ $\kappa \in \omega$) or
	$\kappa = \aleph_\alpha$ for some $\alpha \in \On$.
\end{lemma}
\begin{proof}
	Assume $\kappa$ is infinite, and take $\alpha$ minimal with $\aleph_\alpha \ge \kappa$.
	Suppose for contradiction that we have $\aleph_\alpha > \kappa$.
	We may assume $\alpha > 0$, since the case $\alpha = 0$ is trivial.

	If $\alpha = \ol\alpha + 1$ is a successor, then
	\[ \aleph_{\ol\alpha} < \kappa < \aleph_{\alpha}
		= (\aleph_{\ol\alpha})^+ \]
	which contradicts the fact the definition of the successor cardinal.
	
	If $\alpha = \lambda$ is a limit ordinal, then $\aleph_\lambda$ is the
	supremum $\bigcup_{\gamma < \lambda} \aleph_\gamma$.
	So there must be some $\gamma < \lambda$ has $\aleph_\gamma > \kappa$,
	which contradicts the minimality of $\alpha$.
\end{proof}

\begin{definition}
	An infinite cardinal which is not a successor cardinal
	is called a \vocab{limit cardinal}.
	It is exactly those cardinals of the form $\aleph_\lambda$,
	for $\lambda$ a limit ordinal, plus $\aleph_0$.
\end{definition}


\section{Cardinal Arithmetic}
\prototype{$\aleph_0 \cdot \aleph_0 = \aleph_0 + \aleph_0 = \aleph_0$}
Recall the way we set up ordinal arithmetic.
Note that in particular, $\omega + \omega > \omega$ and $\omega^2 > \omega$.
Since cardinals count size, this property is undesirable, and
we want to have
\begin{align*}
	\aleph_0 + \aleph_0 &= \aleph_0 \\
	\aleph_0 \cdot \aleph_0 &= \aleph_0
\end{align*}
because $\omega + \omega$ and $\omega \cdot \omega$ are countable.
In the case of cardinals, we simply ``ignore order''.

The definition of cardinal arithmetic is as expected:
\begin{definition}[Cardinal Arithmetic]
	Given cardinals $\kappa$ and $\mu$, define
	\[ \kappa + \mu
		\defeq
		\left\lvert 
		\left( \left\{ 0 \right\} \times \kappa \right)
		\cup
		\left( \left\{ 1 \right\} \times \mu \right)
		\right\rvert
	\]
	and
	\[
		k \cdot \mu
		\defeq
		\left\lvert \mu \times \kappa \right\rvert
		.
	\]
\end{definition}


\begin{ques}
	Check this agrees with what you learned in pre-school
	for finite cardinals.
\end{ques}

\begin{abuse}
	This is a slight abuse of notation since we are using
	the same symbols as for ordinal arithmetic,
	even though the results are different ($\omega \cdot \omega = \omega^2$
	but $\aleph_0 \cdot \aleph_0 = \aleph_0$).
	In general, I'll make it abundantly clear whether I am talking
	about cardinal arithmetic or ordinal arithmetic.
\end{abuse}
To help combat this confusion, we use separate symbols for ordinals and cardinals.
Specifically, $\omega$ will always refer to $\{0,1,\dots\}$ viewed as an ordinal;
$\aleph_0$ will always refer to the same set viewed as a cardinal.
More generally,
\begin{definition}
	Let $\omega_\alpha = \aleph_\alpha$ viewed as an ordinal.
\end{definition}

However, as we've seen already we have that $\aleph_0 \cdot \aleph_0 = \aleph_0$.
In fact, this holds even more generally:

\begin{theorem}[Infinite Cardinals Squared]
	Let $\kappa$ be an infinite cardinal.
	Then $\kappa \cdot \kappa = \kappa$.
\end{theorem}
\begin{proof}
	Obviously $\kappa \cdot \kappa \ge \kappa$,
	so we want to show $\kappa \cdot \kappa \le \kappa$.

	The idea is to repeat the same proof that we had for $\aleph_0 \cdot \aleph_0 = \aleph_0$,
	so we re-iterate it here. We took the ``square'' of elements of $\aleph_0$, and then
	\emph{re-ordered} it according to the diagonal:
	\[
	\begin{array}{l|cccccc}
		  & 0 & 1 & 2 & 3 & 4 & \dots \\ \hline
		0 & 0 & 1 & 3 & 6 & 10 & \dots \\
		1 & 2 & 4 & 7 & 11 & \dots & \\
		2 & 5 & 8 & 12 & \dots & & \\
		3 & 9 & 13 & \dots & & & \\
		4 & 14 & \dots & & & &
	\end{array}
	\]
	Let's copy this idea for a general $\kappa$.

	We proceed by transfinite induction on $\kappa$.
	The base case is $\kappa = \aleph_0$, done above.
	For the inductive step, first we put the ``diagonal'' ordering $<_{\text{diag}}$
	on $\kappa \times \kappa$ as follows:
	for $(\alpha_1, \beta_1)$ and $(\alpha_1, \beta_2)$ in $\kappa \times \kappa$
	we declare $(\alpha_1, \beta_1) <_{\text{diag}} (\alpha_2, \beta_2)$ if
	\begin{itemize}
		\ii $\max \left\{ \alpha_1, \beta_1 \right\} < \max \left\{ \alpha_2, \beta_2 \right\}$
		(they are on different diagonals), or
		\ii $\max \left\{ \alpha_1, \beta_1 \right\} = \max \left\{ \alpha_2, \beta_2 \right\}$
		and $\alpha_1 < \alpha_2$ (same diagonal).
	\end{itemize}
	
	Then $<_{\text{diag}}$ is a well-ordering of $\kappa \times \kappa$,
	so we know it is in order-preserving bijection with some ordinal $\gamma$.
	Our goal is to show that $\left\lvert \gamma \right\rvert \le \kappa$.
	To do so, it suffices to prove that for any $\ol\gamma \in \gamma$,
	we have $\left\lvert \ol\gamma \right\rvert < \kappa$.

	Suppose $\ol\gamma$ corresponds to the point $(\alpha, \beta) \in \kappa$
	under this bijection.
	If $\alpha$ and $\beta$ are both finite, then certainly $\ol\gamma$ is finite too.
	Otherwise, let $\ol\kappa = \max \{\alpha, \beta\} < \kappa$;
	then the number of points below $\ol\gamma$ is at most
	\[ 
		\left\lvert \alpha \right\rvert \cdot \left\lvert \beta \right\rvert
		\le \ol\kappa \cdot \ol\kappa
		= \ol\kappa
	\]
	by the inductive hypothesis.
	So $\left\lvert \ol\gamma \right\rvert \le \ol\kappa < \kappa$ as desired.
\end{proof}

From this it follows that cardinal addition and multiplication is really boring:
\begin{theorem}[Infinite Cardinal Arithmetic is Trivial]
	Given cardinals $\kappa$ and $\mu$, one of which is infinite,
	we have \[ \kappa \cdot \mu = \kappa + \mu = \max\left( \kappa, \mu \right).\]
\end{theorem}
\begin{proof}
	The point is that both of these are less than the square of the maximum.
	Writing out the details:
	\begin{align*}
		\max \left( \kappa, \mu \right)
		&\le \kappa + \mu \\ 
		&\le \kappa \cdot \mu \\ 
		&\le \max \left( \kappa, \mu \right) \cdot \max \left( \kappa, \mu  \right) \\
		&= \max\left( \kappa, \mu \right). \qedhere
	\end{align*}
\end{proof}




\section{Cardinal Exponentiation}
\prototype{$2^\kappa = \left\lvert \PP(\kappa) \right\rvert$.}
\begin{definition}
	Suppose $\kappa$ and $\lambda$ are cardinals.
	Then
	\[ \kappa^\lambda
		\defeq \left\lvert \mathscr F(\lambda, \kappa) \right\rvert.
	\]
	Here $\mathscr F(A,B)$ is the set of functions from $A$ to $B$.
\end{definition}

\begin{abuse}
	As before, we are using the same notation for
	both cardinal and ordinal arithmetic. Sorry!
\end{abuse}

In particular, $2^\kappa = \left\lvert \PP(\kappa) \right\rvert > \kappa$,
and so from now on we can use the notation $2^\kappa$ freely.
Note that this is totally different from ordinal arithmetic;
there we had $2^\omega = \bigcup_{n\in\omega} 2^n = \omega$.
In cardinal arithmetic $2^{\aleph_0} > \aleph_0$.

I have unfortunately not told you what $2^{\aleph_0}$ equals.
A natural conjecture is that $2^{\aleph_0} = \aleph_1$; this is called the
\vocab{Continuum Hypothesis}.
It turns out to that this is \emph{undecidable} -- it is not possible
to prove or disprove this from the $\ZFC$ axioms.

\section{Cofinality}
\prototype{$\aleph_0$, $\aleph_1$, \dots\ are all regular, but $\aleph_\omega$ has cofinality $\omega$.}

\begin{definition}
	Let $\lambda$ be a limit ordinal, and $\alpha$ another ordinal.
	A map $f : \alpha \to \lambda$ of ordinals is called \vocab{cofinal}
	if for every $\ol\lambda < \lambda$, there is some $\ol\alpha \in \alpha$
	such that $f(\ol\alpha) \ge \ol\lambda$.
	In other words, the map reaches arbitrarily high into $\lambda$.
\end{definition}
\begin{example}
	[Example of a Cofinal Map]
	\listhack
	\begin{enumerate}[(a)]
		\ii The map $\omega \to \omega^\omega$ by $n \mapsto \omega^n$ is cofinal.
		\ii For any ordinal $\alpha$, the identity map $\alpha \to \alpha$ is cofinal.
	\end{enumerate}
\end{example}

\begin{definition}
	Let $\lambda$ be a limit ordinal.
	The \vocab{cofinality} of $\lambda$, denoted $\cof(\lambda)$,
	is the smallest ordinal $\alpha$ such that there is a cofinal map
	$\alpha \to \lambda$.
\end{definition}
\begin{ques}
	Why must $\alpha$ be an infinite cardinal?
\end{ques}

Usually, we are interested in taking the cofinality of a cardinal $\kappa$.

Pictorially, you can imagine standing at the bottom of the universe and looking
up the chain of ordinals to $\kappa$.
You have a machine gun and are firing bullets upwards, and you want to get arbitrarily
high but less than $\kappa$.
The cofinality is then the number of bullets you need to do this.

We now observe that ``most'' of the time, the cofinality of a cardinal is itself.
Such a cardinal is called \vocab{regular}.
\begin{example}[$\aleph_0$ is Regular]
	$\cof(\aleph_0) = \aleph_0$, because no finite subset of $\omega$ can reach arbitrarily high.
\end{example}
\begin{example}[$\aleph_1$ is Regular]
	$\cof(\aleph_1) = \aleph_1$.
	Indeed, assume for contradiction that some countable
	set of ordinals $A = \{ \alpha_0, \alpha_1, \dots \} \subseteq \omega_1$
	reaches arbitrarily high inside $\omega_1$.
	Then $\Lambda = \cup A$ is a \emph{countable} ordinal,
	because it is a countable union of countable ordinals.
	In other words $\Lambda \in \omega_1$.
	But $\Lambda$ is an upper bound for $A$, contradiction.
\end{example}
On the other hand, there \emph{are} cardinals which are not regular;
since these are the ``rare'' cases we call them \vocab{singular}.
\begin{example}[$\aleph_\omega$ is Not Regular]
	Notice that $\aleph_0 < \aleph_1 < \aleph_2 < \dots$ reaches
	arbitrarily high in $\aleph_\omega$, despite only having $\aleph_0$ terms.
	It follows that $\cof(\aleph_\omega) = \aleph_0$.
\end{example}

We now confirm a suspicion you may have:
\begin{theorem}
	[Successor Cardinals Are Regular]
	If $\kappa = \ol\kappa^+$ is a successor cardinal,
	then it is regular.
\end{theorem}
\begin{proof}
	We copy the proof that $\aleph_1$ was regular.

	Assume for contradiction that for some $\mu \le \ol\kappa$,
	there are $\mu$ sets reaching arbitrarily high in $\kappa$ as a cardinal.
	Observe that each of these sets must have cardinality at most $\ol\kappa$.
	We take the union of all $\mu$ sets, which gives an ordinal $\Lambda$
	serving as an upper bound.

	The number of elements in the union is at most
	\[ \#\text{sets} \cdot \#\text{elms}
		\le \mu \cdot \ol\kappa = \ol\kappa \]
	and hence $\left\lvert \Lambda \right\rvert \le \ol\kappa < \kappa$.
\end{proof}

\section{Inaccessible Cardinals}
So, what about limit cardinals?
It seems to be that most of them are singular: if $\aleph_\lambda \ne \aleph_0$ is a limit ordinal,
then the sequence $\{\aleph_\alpha\}_{\alpha \in \lambda}$ (of length $\lambda$) is certainly cofinal.

\begin{example}[Beth Fixed Point]
	Consider the monstrous cardinal
	\[ \kappa = \aleph_{\aleph_{\aleph_{\ddots}}}. \]
	This might look frighteningly huge, as $\kappa = \aleph_\kappa$,
	but its cofinality is $\omega$ as it is the limit of the sequence
	\[ \aleph_0, \aleph_{\aleph_0}, \aleph_{\aleph_{\aleph_0}}, \dots \]
\end{example}

More generally, one can in fact prove that
\[ \cof(\aleph_\lambda) = \cof(\lambda). \]
But it is actually conceivable that $\lambda$ is so large
that $\left\lvert \lambda \right\rvert = \left\lvert \aleph_\lambda \right\rvert$.

A regular limit cardinal other than $\aleph_0$ has a special name: it is \vocab{weakly inaccessible}.
Such cardinals are so large that it is impossible to prove or disprove their existence in $\ZFC$.
It is the first of many so-called ``large cardinals''.

An infinite cardinal $\kappa$ is a strong limit cardinal if
\[ \forall \ol\kappa < \kappa \quad 2^{\ol\kappa} < \kappa \]
for any cardinal $\ol\kappa$.  For example, $\aleph_0$ is a strong limit cardinal.
\begin{ques}
	Why must strong limit cardinals actually be limit cardinals?
	(This is offensively easy.)
\end{ques}
A regular strong limit cardinal other than $\aleph_0$
is called \vocab{strongly inaccessible}.

\section\problemhead
\begin{problem}
	Compute $\left\lvert V_\omega \right\rvert$.
\end{problem}

\begin{problem}
	Prove that for any limit ordinal $\alpha$, $\cof(\alpha)$ is a \emph{regular} cardinal.
	\begin{hint}
		Rearrange the cofinal maps to be nondecreasing.
	\end{hint}
\end{problem}

\begin{sproblem}
	[Strongly Inaccessible Cardinals]
	\label{prob:strongly_inaccessible}
	Show that for any strongly inaccessible $\kappa$,
	we have $\left\lvert V_\kappa \right\rvert = \kappa$.
\end{sproblem}

\begin{problem}
	[Konig's Theorem]
	Show that \[ \kappa^{\cof(\kappa)} > \kappa \] for every infinite cardinal $\kappa$.
\end{problem}


\chapter{Inner Model Theory}
Model theory is \emph{really} meta, so you will have to pay attention here.

Roughly, a ``model of $\ZFC$'' is a set with a binary relation that satisfies the $\ZFC$ axioms,
just as a group is a set with a binary operation that satisfies the group axioms.
Unfortunately, unlike with groups, it is very hard for me to give interesting examples of models,
for the simple reason that we are literally trying to model the entire universe.

\section{Model}
\prototype{$(\omega, \in)$ obeys $\PowerSet$, $V_\kappa$ is a model for $\kappa$ inaccessible (later).}
\begin{definition}
	A \vocab{model} $\MM$ consists of a set $M$ and a
	binary relation $E \subseteq M \times M$.
	(The $E$ relation is the ``$\in$'' for the model.)
\end{definition}
\begin{remark}
	I'm only considering \emph{set-sized} models where $M$ is a set.
	Experts may be aware that I can actually play with $M$ being a class,
	but that would require too much care for now.
\end{remark}
If you have a model, you can ask certain things about it.
For example, you can ask ``does it satisfy $\EmptySet$?''.
Let me give you an example of what I mean, and then make it rigorous.
\begin{example}
	[A Stupid Model]
	Let's take $\MM = (M,E) = \left( \omega, \in \right)$.
	This is not a very good model of $\ZFC$, but let's see if we can
	make sense of some of the first few axioms.
	\begin{enumerate}[(a)]
		\ii $\MM$ satisfies $\Extensionality$, which is the sentence
		\[ \forall x \forall y \forall a : \left( a \in x \iff a \in y \right) \implies x = y. \]
		This just follows from the fact that $E$ is actually $\in$.

		\ii $\MM$ satisfies $\EmptySet$, which is the sentence
		\[ \exists a : \forall x \; \neg (x \in a). \]
		Namely, take $a = \varnothing \in \omega$.

		\ii $\MM$ does not satisfy $\Pairing$, since $\{1,3\}$ is not in $\omega$,
		even though $1, 3 \in \omega$.

		\ii Miraculously, $\MM$ satisfies $\Union$, since for any $n \in \omega$,
		$\cup n$ is $n-1$ (unless $n=0$).
		The Union axiom statements that
		\[ \forall a \exists z \quad \forall x \; (x \in z) \iff (\exists y : x \in y \in z). \]
		An important thing to notice is that the ``$\forall a$'' ranges only over
		the sets in the model of the universe, $\MM$.
	\end{enumerate}
\end{example}
\begin{example}
	[Very Important: This Stupid Model Satisfies $\PowerSet$]
	Most incredibly of all: $\MM = (\omega, \in)$ satisfies $\PowerSet$.
	This is a really important example.
	
	You might think this is ridiculous. Look at $2 = \{0,1\}$.
	The power set of this is $\{0, 1, 2, \{1\}\}$ which is not in the model, right?

	Well, let's look more closely at $\PowerSet$. It states that:
	\[ \forall x \exists a \forall y (y \in a \iff y \subseteq x). \]
	What happens if we set $x = 2 = \{0,1\}$?
	Well, actually, we claim that $a = 3 = \{0,1,2\}$ works.
	The key point is ``for all $y$'' -- this \emph{only ranges over the objects in $\MM$}.
	In $\MM$, the only subsets of $2$ are $0 = \varnothing$,
	$1 = \{0\}$ and $2 = \{0,1\}$.
	The ``set'' $\{1\}$ in the ``real world'' (in $V$) is not a set in the model $\MM$.

	In particular, you might say that in this strange new world,
	we have $2^n = n+1$, since $n = \{0,1,\dots,n-1\}$ really does
	have only $n+1$ subsets.
\end{example}

\begin{example}
	[Sentences with Parameters]
	The sentences we ask of our model are allowed to have ``parameters'' as well.
	For example, if $\MM = (\omega, \in)$ as before then $\MM$ satisfies the sentence
	\[ \forall x \in 3 (x \in 5). \]
\end{example}

\section{Sentences and Satisfaction}
With this intuitive notion, we can define what it means for a model to satisfy a sentence.
\begin{definition}
Note that any sentence $\phi$ can be written in one of the following five forms:
\begin{itemize}
	\ii $x \in y$
	\ii $x = y$
	\ii $\neg \psi$ (``not $\psi$'') for some shorter sentence $\psi$
	\ii $\psi_1 \lor \psi_2$ (```$\psi_1$ or $\psi_2$'')
	for some shorter sentences $\psi_1$, $\psi_1$
	\ii $\exists x \psi$ (``exists $x$'') for some shorter sentence $\psi$.
\end{itemize}
\end{definition}
\begin{ques}
	What happened to $\land$ (and) and $\forall$ (for all)?
	(Hint: use $\neg$.)
\end{ques}
Often (almost always, actually) we will proceed by so-called ``induction on formula complexity'',
meaning that we define or prove something by induction using this.
Note that we require all formulas to be finite.

Now suppose we have a sentence $\phi$, like $a = b$ or $\exists a \forall x \neg (x \in a)$,
plus a model $\MM = (M,E)$.
We want to ask whether $\MM$ satisfies $\phi$.

To give meaning to this, we have to designate certain variables as \vocab{parameters}.
For example, if I asked you 
\begin{quote}
	``Does $a=b$?''
\end{quote}
the first question you would ask is what $a$ and $b$ are.
So $a$, $b$ would be parameters: I have to give them values for this sentence to make sense.

On the other hand, if I asked you
\begin{quote}
	``Does $\exists a \forall x \neg (x \in a)$?''
\end{quote}
then you would just say ``yes''.
In this case, $x$ and $a$ are \emph{not} parameters.
In general, parameters are those variables whose meaning is not given by some $\forall$ or $\exists$.

In what follows, we will let $\phi(x_1, \dots, x_n)$ denote a formula $\phi$,
whose parameters are $x_1$, \dots, $x_n$.
Note that possibly $n=0$, for example all $\ZFC$ axioms have no parameters.

\begin{ques}
	Try to guess the definition of satisfaction before reading it below.
	(It's not very hard to guess!)
\end{ques}

\begin{definition}
	Let $\MM=(M,E)$ be a model.
	Let $\phi(x_1, \dots, x_n)$ be a sentence, and let $b_1, \dots, b_n \in M$.
	We will define a relation
	\[ \MM \vDash \phi[b_1, \dots, b_n] \]
	and say $\MM$ \vocab{satisfies} the sentence $\phi$ with parameters $b_1, \dots, b_n$.

	The relationship is defined by induction on formula complexity as follows:
	\begin{itemize}
		\ii If $\phi$ is ``$x_1=x_2$'' then $\MM \vDash \phi[b_1, b_2] \iff b_1 = b_2$.
		\ii If $\phi$ is ``$x_1\in x_2$'' then $\MM \vDash \phi[b_1, b_2] \iff b_1 \; E \; b_2$. \\
		(This is what we mean by ``$E$ interprets $\in$''.)
		\ii If $\phi$ is ``$\neg \psi$'' then
		$\MM \vDash \phi[b_1, \dots, b_n] \iff \MM \not\vDash \phi[b_1, \dots, b_n]$.
		\ii If $\phi$ is ``$\psi_1 \lor \psi_2$'' then $\MM \vDash \phi[b_1, \dots, b_n]$
		means $\MM \vDash \psi_i[b_1, \dots, b_n]$ for some $i=1,2$.
		\ii Most important case: suppose $\phi$ is $\exists x \psi(x,x_1, \dots, x_n)$.
		Then $\MM \vDash \phi[b_1, \dots, b_n]$ if and only if 
		\[ \exists b \in M \text{ such that } \MM \vDash \psi[b, b_1, \dots, b_n]. \]
		Note that $\psi$ has one extra parameter.
	\end{itemize}
\end{definition}
Notice where the information of the model actually gets used.
We only ever use $E$ in interpreting $x_1 \in x_2$; unsurprising.
But we only ever use the set $M$ when we are running over $\exists$ (and hence $\forall$).
That's well-worth keeping in mind:
\begin{moral}
	The behavior of a model essentially comes from $\exists$ and $\forall$,
	which search through the entire model $M$.
\end{moral}

And finally,
\begin{definition}
	A \vocab{model of $\ZFC$} is a model $\MM = (M,E)$ satisfying all $\ZFC$ axioms.
\end{definition}

We are especially interested in models of the form $(M, \in)$, where $M$ is a \emph{transitive} set.
(We want our universe to be transitive,-
otherwise we would have elements of sets which are not themselves
in the universe, which is very strange.)
Such a model is called a \vocab{transitive model}.
\begin{abuse}
	If $M$ is a transitive set, the model $(M, \in)$ will be abbreviated to just $M$.
\end{abuse}
\begin{definition}
	An \vocab{inner model} of $\ZFC$ is a transitive model satisfying $\ZFC$.
\end{definition}

\section{The Levy Hierarchy}
\prototype{$\mathtt{isSubset}(x,y)$ is absolute. The axiom
$\EmptySet$ is $\Sigma_1$, $\mathtt{isPowerSetOf}(X,x)$ is $\Pi_1$.}
A key point to remember is that the behavior of a model is largely determined by $\exists$ and $\forall$.
It turns out we can say even more than this.

Consider a formula such as
\[ \mathtt{isEmpty}(x) : \neg \exists a (a \in x) \]
which checks whether a given set $x$ has a nonempty element.
Technically, this has an ``$\exists$'' in it.
But somehow this $\exists$ does not really search over the entire model,
because it is \emph{bounded} to search in $x$.
That is, we might informally rewrite this as
\[ \neg (\exists x \in a) \]
which doesn't fit into the strict form,
but points out that we are only looking over $a \in x$.
We call such a quantifier a \vocab{bounded quantifier}.
%and write it
%in the way we see it in most mathematics, such as
%\[ (\exists x \in a) \quad\text{or}\quad (\forall x \in a). \]
%To be painfully explicit,
%$\exists x \in a \psi$ is short for $\exists x (x \in a \land \psi)$,
%while $\forall x \in a \psi$ is short for $\forall x (x \in a \implies \psi)$.

We like sentences with bounded quantifiers because they designate
properties which are \vocab{absolute} over transitive models.
It doesn't matter how strange your surrounding model $M$ is.
As long as $M$ is transitive, 
\[ M \vDash \mathtt{isEmpty}[\varnothing] \]
will always hold.
Similarly, the sentence
\[ \mathtt{isSubset}(x,y) : x \subseteq y \text { i.e. } \forall a \in x (a \in y). \]
Sentences with this property are called $\Sigma_0$ or $\Pi_0$.

The situation is different with a sentence like
\[
	\mathtt{isPowerSetOf}(y,x) :
	\forall z \left( z \subseteq x \iff z \in y  \right)
\]
which in English means ``$y$ is the power set of $x$'', or just $y = \PP(x)$.
The $\forall z$ is \emph{not} bounded here.
This weirdness is what allows things like
\[ \omega \vDash \text{``$\{0,1,2\}$ is the power set of $\{0,1\}$''} \]
and hence
\[ \omega \vDash \PowerSet \]
which was our stupid example earlier.
The sentence $\mathtt{isPowerSetOf}$ consists of an unbounded $\forall$ followed
by an absolute sentence, so we say it is $\Pi_1$.

More generally, the \vocab{Levy hierarchy} keeps track of how bounded our
quantifiers are.
Specifically,
\begin{itemize}
	\ii Formulas which have only bounded quantifiers are $\Delta_0 = \Sigma_0 = \Pi_0$.
	\ii Formulas of the form $\exists x_1 \dots \exists x_k \psi$ where $\psi$ is $\Pi_n$
	are consider $\Sigma_{n+1}$.
	\ii Formulas of the form $\forall x_1 \dots \forall x_k \psi$ where $\psi$ is $\Sigma_n$
	are consider $\Pi_{n+1}$.
\end{itemize}
(A formula which is both $\Sigma_n$ and $\Pi_n$ is said $\Delta_n$, but we won't
use this except for $n=0$.)

\begin{example}
	[Examples of $\Delta_0$ Sentences]
	\listhack
	\begin{enumerate}[(a)]
		\ii The sentences $\mathtt{isEmpty}(x)$, $x \subseteq y$, as discussed above.
		\ii The formula ``$x$ is transitive'' can be expanded as a $\Delta_0$ sentence.
		\ii The formula ``$x$ is an ordinal'' can be expanded as a $\Delta_0$ sentence.
	\end{enumerate}
\end{example}
\begin{exercise}
	Write out the expansions for ``$x$ is transitive'' and ``$x$ is ordinal''
	in a $\Delta_0$ form.
\end{exercise}
\begin{example}
	[More Complex Formulas]
	\listhack
	\begin{enumerate}[(a)]
		\ii The axiom $\EmptySet$ is $\Sigma_1$; it is $\exists a (\mathtt{isEmpty}(a))$,
		and $\mathtt{isEmpty}(a)$ is $\Delta_0$.
		\ii The formula ``$y = \PP(x)$'' is $\Pi_1$, as discussed above.
		\ii The formula ``$x$ is countable'' is $\Sigma_1$.
		One way to phrase it is ``$\exists f$ an injective map $x \injto \omega$'',
		which necessarily has an unbounded ``$\exists f$''.
		\ii The axiom $\PowerSet$ is $\Pi_3$:
		\[ \forall y \exists P \forall x (x\subseteq y \iff x \in P). \]
	\end{enumerate}
\end{example}

\section{Substructures, and Tarski-Vaught}
Let $\MM_1 = (M_1, E_1)$ and $\MM_2 = (M_2, E_2)$ be models.
\begin{definition}
	We say that $\MM_1 \subseteq \MM_2$ if $M_1 \subseteq M_2$ and
	$E_1$ agrees with $E_2$; we say $\MM_1$ is a \vocab{substructure} of $\MM_2$.
\end{definition}

That's boring. The good part is:
\begin{definition}
	We say $\MM_1 \prec \MM_2$, or $\MM_1$ is an \vocab{elementary substructure} of $\MM_2$,
	if for \emph{every} sentence $\phi(x_1, \dots, x_n)$
	and parameters $b_1, \dots, b_n \in M_1$, we have
	\[
		\MM_1 \vDash \phi[b_1, \dots, b_n] \iff
		\MM_2 \vDash \phi[b_1, \dots, b_n].
	\]
\end{definition}
In other words, $\MM_1$ and $\MM_2$ agree on every sentence possible.
Note that the $b_i$ have to come from $M_1$; if the $b_i$ came from $\MM_2$ then
asking something of $\MM_1$ wouldn't make sense.

Let's ask now: how would $\MM_1 \prec \MM_2$ fail to be true?
If we look at the possibly sentences, none of the atomic formulas,
nor the ``$\land$'' and ``$\neg$'', are going to cause issues.

The intuition you should be getting by now is that things go
wrong once we hit $\forall$ and $\exists$.
They won't go wrong for bounded quantifiers.
But unbounded quantifiers search the entire model, and that's where things go wrong.

To give a ``concrete example'':
imagine $\MM_1$ is MIT, and $\MM_2$ is the state of Massachusetts.
If $\MM_1$ thinks there exist hackers at MIT,
certainly there exist hackers in Massachusetts.
Where things go wrong is something like:
\[ \MM_2 \vDash \text{``$\exists x$ : $x$ is a course numbered $> 50$.''}. \]
This is true for $\MM_2$ because we can take the witness $x = \text{Math 55}$, say.
But it's false for $\MM_1$, because at MIT all courses are numbered $18.701$ or something similar.
\begin{moral}
	The issue is that the \emph{witness}
	for statements in $\MM_2$ do not necessarily propagate up
	down to witnesses for $\MM_1$, even though they do from $\MM_1$ to $\MM_2$.
\end{moral}

The Tarski-Vaught test says this is the only impediment:
if every witness in $\MM_2$ can be replaced by one in $\MM_1$ then $\MM_1 \prec \MM_2$.
\begin{lemma}
	[Tarski-Vaught]
	Let $\MM_1 \subseteq \MM_2$.
	Then $\MM_1 \prec \MM_2$ if and only if for
	every sentence $\phi(x, x_1, \dots, x_n)$ and parameters $b_1, \dots, b_n \in M_1$:
	if there is a witness $\tilde b \in M_2$ to $\MM_2 \vDash \phi(\tilde b, b_1 \dots, b_n)$
	then there is a witness $b \in M_1$ to $\MM_1 \vDash \phi(b, b_1, \dots, b_n)$.
\end{lemma}
\begin{proof}
	Easy after the above discussion.
	To formalize it, use induction on formula complexity.
\end{proof}

\section{Obtaining the Axioms of $\ZFC$}
Extending the above ideas, one can obtain without much difficulty the following.
The idea is that almost all the $\ZFC$ axioms are just $\Sigma_1$ claims about certain desired sets,
and so verifying an axiom reduces to checking some appropriate ``closure'' condition:
that the witness to the axiom is actually in the model.

For example, the $\EmptySet$ axiom is ``$\exists a (\mathtt{isEmpty}(a))$'',
and so we're happy as long as $\varnothing \in M$, which is of course
true for any nonempty transitive set $M$.

\begin{lemma}[Transitive Sets Inheriting $\ZFC$]
	\label{lem:transitive_ZFC}
	Let $M$ be a nonempty transitive set. Then
	\begin{enumerate}[(i)]
		\ii $M$ satisfies $\Extensionality$, $\Foundation$, $\EmptySet$.
		\ii $M \vDash \Pairing$ if $x,y \in M \implies \{x,y\} \in M$.
		\ii $M \vDash \Union$ if $x \in M \implies \cup x \in M$.
		\ii $M \vDash \PowerSet$ if $x \in M \implies \PP(x) \cap M \in M$.
		\ii $M \vDash \Replacement$ if for every $x \in M$
		and every function $F : x \to M$
		which is $M$-definable with parameters,
		we have $F``x \in M$ as well.
		\ii $M \vDash \Infinity$ as long as $\omega \in M$.
	\end{enumerate}
\end{lemma}
Here, a set $X \subseteq M$ is \vocab{$M$-definable with parameters}
if it can be realized as
\[ X = \left\{ x \in M \mid \phi[x, b_1, \dots, b_n] \right\} \]
for some (fixed) choice of parameters $b_1,\dots,b_n \in M$.
We allow $n=0$, in which case we say $X$ is \vocab{$M$-definable without parameters}.
Note that $X$ need not itself be in $M$!
As a trivial example, $X = M$ is $M$-definable without parameters
(just take $\phi[x]$ to always be true), and certainly we do not have $X \in M$.
\begin{exercise}
	Verify (i)-(iv) above.
\end{exercise}
\begin{remark}
	Converses to the statements of \Cref{lem:transitive_ZFC}
	are true for all claims other than (vii).
\end{remark}

\section{Mostowski Collapse}
Up until now I have been only talking about transitive models,
because they were easier to think about.
Here's a second, better reason we might only care about transitive models.

\begin{lemma}
	[Mostowski Collapse]
	Let $\mathscr X = (X,E)$ be a model
	such that $\mathscr X \vDash \Extensionality + \Foundation$.
	Then there exists an isomorphism $\pi : \mathscr X \to M$ for
	a transitive model $M = (M,\in)$.
\end{lemma}

This is also called the \emph{transitive collapse}.
In fact, both $\pi$ and $M$ are unique.

\begin{proof}
	The idea behind the proof is very simple.
	Since $E$ is well-founded and extensional, we can look at the
	$E$-minimal element $x_\varnothing$ of $X$ with respect to $E$.
	Clearly, we want to send that to $0 = \varnothing$.

	Then we take the next-smallest set under $E$, and send it to $1 = \{\varnothing\}$.
	We ``keep doing this''; it's not hard to see this does exactly what we want.

	To formalize, define $\pi$ by transfinite recursion:
	\[ \pi(x) \defeq \left\{ \pi(y) \mid y \; E \; x \right\}. \]
	This $\pi$, by construction, does the trick.
\end{proof}

The picture of this is quite ``collapsing'' the elements of $M$ down
to the bottom of $V$, hence the name.
\missingfigure{Picture of Mostowski collapse}


\section{Adding an Inaccessible, Skolem Hulls, and Going Insane}
\prototype{$V_\kappa$}
At this point you might be asking, well, where's my model of $\ZFC$?

I unfortunately have to admit now: $\ZFC$ can never prove that there is a model of $\ZFC$
(unless $\ZFC$ is inconsistent, but that would be even worse).
This is a result called G\"odel's Incompleteness Theorem.

Nonetheless, with some very modest assumptions added, we can actually show that a model \emph{does} exist:
for example, assuming that there exists a strongly inaccessible cardinal $\kappa$ would do the trick,
$V_\kappa$ will be such a model (\Cref{prob:inaccessible_model}).
Intuitively you can see why: $\kappa$ is so big that any set of rank lower than it can't escape it
even if we take their power sets, or any other method that $\ZFC$ lets us do.
I encourage you to try \Cref{prob:inaccessible_model} now.

More pessimistically, this shows that it's impossible to prove in $\ZFC$ that such a $\kappa$ exists.
Nonetheless, we now proceed under $\ZFC^+$ for convenience, which adds the existence of such a $\kappa$
as a final axiom.
So we now have a model $V_\kappa$ to play with. Joy!

Great. Now we do something \emph{really} crazy.
\begin{theorem}[Countable Transitive Model]
	Assume $\ZFC^+$. Then there exists a transitive model $M$ of $\ZFC$
	such that $M$ is a \emph{countable} set.
\end{theorem}
\begin{proof}
	I'm telling you, this is insane. Fasten your seat belts.

	Start with the set $X_0 = \varnothing$.
	Then for every integer $n$, we do the following to get $X_{n+1}$.
	\begin{itemize}
		\ii Start with $X_{n+1}$ containing very element of $X_n$.
		\ii Consider a formula $\phi(x, x_1, \dots, x_n)$
		and $b_1, \dots, b_n$ in $X_n$.
		Suppose that $M$ thinks there is an $b \in M$ for which
		\[ M \vDash \phi[b, b_1, \dots, b_n]. \]
		We then add in the element $b$ to $X_{n+1}$.
		\ii We do this for \emph{EVERY POSSIBLE FORMULA IN THE LANGUAGE OF SET THEORY}.
		We also have to put in \emph{EVERY POSSIBLE SET OF PARAMETERS} from the previous set $X_n$.
	\end{itemize}
	At every step $X_n$ is countable.
	Reason: there are countably many possible finite sets of parameters in $X_n$,
	and countably many possible formulas, so in total we only ever add in countably many things
	at each step.
	This exhibits an infinite nested sequence of countable sets
	\[ X_0 \subseteq X_1 \subseteq X_2 \subseteq \dots \]
	None of these is a substructure of $M$, because each $X_n$ by relies on witnesses in $X_{n+1}$.
	So we instead \emph{TAKE THE UNION}:
	\[ X = \bigcup_n X_n. \]
	This satisfies the Tarski-Vaught test, and is countable.

	There is one minor caveat: $X$ might not be transitive.
	We don't care, because we just take its Mostowski collapse.
\end{proof}

Please take a moment to admire how insane this is.
It hinges irrevocably on the fact that there are countably many sentences we can write down.

\begin{remark}
	This proof relies heavily on the Axiom of Choice
	when we add in the element $b$ to $X_{n+1}$.
	Without Choice, there is no way of making these decisions all at once.

	Usually, the right way to formalize the Axiom of Choice usage is,
	for every formula $\phi(x, x_1, \dots, x_n)$, to pre-commit (at the very beginning)
	to a function $f_\phi(x_1, \dots, x_n)$, such that given any $b_1, \dots, b_n$
	$f_\phi(b_1, \dots, b_n)$ will spit out the suitable value of $b$ (if one exists).
	Personally, I think this is hiding the spirit of the proof, but it does
	make it clear how exactly Choice is being used.

	These $f_\phi$'s have a name: \vocab{Skolem functions}.
\end{remark}

The trick we used in the proof works in more general settings:
\begin{theorem}
	[Downward L\"owenheim-Skolem Theorem]
	Let $\MM = (M,E)$ be a model, and $A \subseteq M$.
	Then there exists a set $B$ (called the \vocab{Skolem hull} of $A$)
	with $A \subseteq B \subseteq M$,
	such that $(B,E) \prec \MM$, and
	\[ \left\lvert B \right\rvert < \max \left\{ \omega, \left\lvert A \right\rvert \right\}. \]
\end{theorem}
In our case, what we did was simply take $A$ to be the empty set.
\begin{ques}
	Prove this. (Exactly the same proof as before.)
\end{ques}


\section{FAQ's on Countable Models}
The most common one is ``how is this possible?'',
with runner-up ``what just happened''.

Let me do my best to answer the first question.
It seems like there are two things running up against each other:
\begin{enumerate}[(1)]
	\ii $M$ is a transitive model of $\ZFC$, but its universe is uncountable.
	\ii $\ZFC$ tells us there are uncountable sets!
\end{enumerate}
(This has confused so many people it has a name, Skolem's paradox.)

The reason this works I actually pointed out earlier:
\emph{countability is not absolute, it is a $\Sigma_1$ notion}.

Recall that a set $x$ is countable if
\emph{there exists} an injective map $x \injto \omega$.
The first statement just says that \emph{in the universe $V$},
there is a injective map $F: M \injto \omega$.
In particular, for any $x \in M$ (hence $x \subseteq M$, since $M$ is transitive),
$x$ is countable \emph{in $V$}.
This is the content of the first statement.

But for $M$ to be a model of $\ZFC$, $M$ only has to think statements in $\ZFC$ are true.
More to the point, the fact that $\ZFC$ tells us there are uncountable sets means
\[ M \vDash \text{$\exists x$ uncountable}. \]
In other words,
\[ M \vDash \exists x \forall f
	\text{ If $f : x \to \omega$ then $f$ isn't injective}. \]
The key point is the $\forall f$ searches only functions in our tiny model $M$.
It is true that in the ``real world'' $V$, there are injective functions $f : x \to \omega$.
But $M$ has no idea they exist!
It is a brain in a vat: $M$ is oblivious to any information outside it.

So in fact, every ordinal which appears in $M$ is countable in the real world.
It is just not countable in $M$.
Since $M \vDash \ZFC$, $M$ is going to think there is some smallest uncountable cardinal,
say $\aleph_1^M$.
It will be the smallest (infinite) ordinal in $M$
with the property that there is no bijection \emph{in the model $M$}
between $\aleph_1^M$ and $\omega$.
However, we necessarily know that such a bijection is going to exist in the real world $V$.

Put another way, cardinalities in $M$ can look vastly different from those in the real world,
because cardinality is measured by bijections, which I guess is inevitable, but leads to chaos.

\section{Picturing Inner Models}
Here is a picture of a countable transitive model $M$.

\begin{center}
	\begin{asy}
		size(14cm);
		pair A = (12,30);
		pair B = -conj(A);
		pair M = midpoint(A--B);
		pair O = origin;
		MP("V", A, dir(10));
		draw(A--O--B);

		fill(A--O--B--cycle, opacity(0.3)+palecyan);
		MP("M", 0.7*M, 3*dir(0)+dir(45));

		MP("V_0 = \varnothing", origin, dir(-20));
		MP("V_1 = \{\varnothing\}", 0.05*A, dir(0));
		MP("V_2 = \{\varnothing, \{\varnothing\} \}", 0.10*A, dir(0));

		pair A1 = 0.4*A;
		pair B1 = 0.4*B;
		draw(MP("V_\omega", A1, dir(0))--B1);
		draw(MP("V_{\omega+1} = \mathcal P(V_n)", 0.45*A, dir(0))--0.45*B);
		Drawing("\omega", 0.45*M, dir(45));

		filldraw(O--A1--(A1+0.15*M)..(0.7*M)..(B1+0.15*M)--B1--cycle,
			opacity(0.3)+lightgreen, heavygreen+1);
		draw(O--0.7*M, heavygreen+1);

		Drawing("\aleph_1^V", 0.80*M, dir(0));
		Drawing("\aleph_2^V", 0.90*M, dir(0));
		Drawing("\aleph_1^M", 0.55*M, dir(0));
		Drawing("\aleph_2^M", 0.60*M, dir(0));

		pair F = 0.6*B+0.15*A;
		Drawing("f", F, dir(135));
		draw(F--0.55*M, dotted, EndArrow, Margins);
		draw(F--0.45*M, dotted, EndArrow, Margins);

		draw(0.7*M--M);
		MP("\mathrm{On}^V", M, dir(90));
		MP("\mathrm{On}^M", 0.7*M, dir(135));
	\end{asy}
\end{center}

Note that $M$ and $V$ must agree on finite sets,
since every finite set has a formula that can express it.
However, past $V_\omega$ the model and the true universe start to diverge.

The entire model $M$ is countable, so it only occupies a small
portion of the universe, below the first uncountable cardinal $\aleph_1^V$
(where the superscript means ``of the true universe $V$'').
The ordinals in $M$ are precisely the ordinals of $V$ which happen to live inside the model,
because the sentence ``$\alpha$ is an ordinal'' is absolute.
On the other hand, $M$ has only a portion of these ordinals, since it is only
a lowly set, and a countable set at that.
To denote the ordinals of $M$, we write $\On^M$, where the superscript means
``the ordinals as computed in $M$''.
Similarly, $\On^V$ will now denote the ``set of true ordinals''.

Nonetheless, the model $M$ has its own version of the first uncountable
cardinal $\aleph_1^M$.
In the true universe, $\aleph_1^M$ is countable (below $\aleph_1^V$),
but the necessary bijection witnessing this might not be inside $M$.
Thats' why $M$ can think $\aleph_1^M$ is uncountable, 
even if it is a countable cardinal in the original universe.

So our model $M$ is a brain in a vat.
It happens to believe all the axioms of $\ZFC$, and so every
statement that is true in $M$ could conceivably be true in $V$ as well.
But $M$ can't see the universe around it; it has no idea that what it believes is
the uncountable $\aleph_1^M$ is really just an ordinary countable cardinal.

\section\problemhead
\begin{sproblem}
	Show that for any transitive model $M$, the set of ordinals in $M$
	is itself some ordinal.
\end{sproblem}

\begin{dproblem}
	Assume $\MM_1 \subseteq \MM_2$. Show that
	\begin{enumerate}[(a)]
		\ii If $\phi$ is $\Delta_0$,
		then $\MM_1 \vDash \phi[b_1, \dots, b_n] \iff \MM_2 \vDash \phi[b_1, \dots, b_n]$.
		\ii If $\phi$ is $\Sigma_1$,
		then $\MM_1 \vDash \phi[b_1, \dots, b_n] \implies \MM_2 \vDash \phi[b_1, \dots, b_n]$.
		\ii If $\phi$ is $\Pi_1$,
		then $\MM_2 \vDash \phi[b_1, \dots, b_n] \implies \MM_1 \vDash \phi[b_1, \dots, b_n]$.
	\end{enumerate}
	(This should be easy if you've understood the chapter.)
\end{dproblem}

Reflection

\begin{sproblem}
	[Inaccessible Cardinal Produce Models]
	\label{prob:inaccessible_model}
\end{sproblem}



\chapter{Examples of Models}
$V=L$

ultrapower
\chapter{Forcing}
We are now going to introduce Paul Cohen's technique of \vocab{forcing},
which we then use to break the Continuum Hypothesis.

Here is how it works.
Given a transitive model $M$ and a poset $\Po$ inside it,
we can consider a ``generic'' subset $G \subseteq \Po$, where $G$ is not in $M$.
Then, we are going to construct a bigger universe $M[G]$ which contains both $M$ and $G$.
(This notation is deliberately the same as $\ZZ[\sqrt2]$, for example -- in the algebra case,
we are taking $\ZZ$ and adding in a new element $\sqrt 2$, plus everything that can be generated from it.)
By choosing $\Po$ well, we can cause $M[G]$ to have desirable properties.

Picture:

\begin{center}
	\begin{asy}
		size(14cm);
		pair A = (12,30);
		pair B = -conj(A);
		pair M = midpoint(A--B);
		pair O = origin;
		MP("V", A, dir(10));
		draw(A--O--B);

		fill(A--O--B--cycle, opacity(0.3)+palecyan);

		MP("V_0 = \varnothing", origin, dir(-20));
		MP("V_1 = \{\varnothing\}", 0.05*A, dir(0));
		MP("V_2 = \{\varnothing, \{\varnothing\} \}", 0.10*A, dir(0));

		pair A1 = 0.4*A;
		pair B1 = 0.4*B;
		draw(MP("V_\omega", A1, dir(0))--B1);
		draw(MP("V_{\omega+1} = \mathcal P(V_n)", 0.45*A, dir(0))--0.45*B);
		Drawing("\omega", 0.45*M, dir(45));

		filldraw(O--A1--(A1+0.30*M)..(0.85*M)..(B1+0.30*M)--B1--cycle,
			opacity(0.3)+lightgreen, heavygreen+1);
		draw(O--0.85*M, heavygreen+1);
		filldraw(O--(1.3*A1)..(0.85*M)..(1.3*B1)--cycle,
			opacity(0.1)+lightred, heavyred+1);

		Drawing("\aleph_1^V", 0.95*M, dir(0));

		pair F = 0.55*B+0.10*A;
		Drawing("f", F, dir(90));
		draw(F--0.55*M, dotted, EndArrow, Margins);
		draw(F--0.45*M, dotted, EndArrow, Margins);

		Drawing("\aleph_1^M", 0.55*M, dir(45));
		Drawing("\aleph_1^{M[G]}", 0.65*M, dir(45));

		draw(0.85*M--M);
		MP("\mathrm{On}^V", M, dir(90));
		MP("\mathrm{On}^M = \mathrm{On}^{M[G]}", 0.85*M, dir(135));

		MP("M \subseteq M[G]", 0.85*M, 3*dir(0)+dir(45));

		Drawing("\mathbb P", 0.3*M+0.3*A, dir(135));
		Drawing("G", 0.55*A+0.1*B, dir(45));
	\end{asy}
\end{center}

The model $M$ is drawn in green, and its extension $M[G]$ is drawn in red.

The models $M$ and $M[G]$ will share the same ordinals, which is represented here
as $M$ being no taller than $M[G]$.
But one issue with this is that forcing may introduce some new bijections between cardinals of $M$
that were not there originally; this leads to the phenomenon called \vocab{cardinal collapse}:
quite literally, cardinals in $M$ will no longer be cardinals in $M[G]$, and instead just an ordinal.
This is because in the process of adjoining $G$, we may accidentally pick up some bijections which were not in the earlier universe.
In the diagram drawn, this is the function $f$ mapping $\omega$ to $\aleph_1^M$.

In the case of the Continuum Hypothesis, we'll introduce a $\Po$ such that
any generic subset $G$ will ``encode'' $\aleph_2^M$ real numbers.
We'll then show cardinal collapse does not occur, meaning $\aleph_2^{M[G]} = \aleph_2^M$.
Thus $M[G]$ will have $\aleph_2^{M[G]}$ real numbers, as desired.

\section{Setting Up Posets}
\prototype{Infinite Binary Tree}
Let $M$ be a transitive model of $\ZFC$.
Let $\Po = (\Po, \le) \in M$ be a poset with a maximal element $1_\Po$
which lives inside a model $M$.
The elements of $\Po$ are called \vocab{conditions};
because they will force things to be true in $M[G]$.

\begin{definition}
	A subset $D \subseteq \Po$ is \vocab{dense} if for all $p \in \Po$,
	there exists a $q  \in D$ such that $q \le p$.
\end{definition}
Examples of dense subsets include the entire $\Po$ as well
as any downwards ``slice''.

\begin{definition}
	For $p,q \in \Po$ we write $p \parallel q$,
	saying ``$p$ is \vocab{compatible} with $q$'',
	if there is exists $r \in \Po$ with $r \le p$ and $r \le q$.
	Otherwise, we say $p$ and $q$ are \vocab{incompatible}
	and write $p \perp q$.
\end{definition}
\begin{example}[Infinite Binary Tree]
	Let $\Po = 2^{<\omega}$ be the \vocab{infinite binary tree} shown below,
	extended to infinity in the obvious way:
	\begin{center}
		\begin{asy}
			size(8cm);
			pair P = Drawing("\varnothing", (0,4), dir(90));
			pair P0 = Drawing("0", (-5,2), 1.5*dir(90));
			pair P1 = Drawing("1", (5,2),  1.5*dir(90));
			pair P00 = Drawing("00", (-7,0), 1.4*dir(120));
			pair P01 = Drawing("01", (-3,0), 1.4*dir(60));
			pair P10 = Drawing("10", (3,0),  1.4*dir(120));
			pair P11 = Drawing("11", (7,0),  1.4*dir(60));

			pair P000 = Drawing("000", (-8,-3));
			pair P001 = Drawing("001", (-6,-3));
			pair P010 = Drawing("010", (-4,-3));
			pair P011 = Drawing("011", (-2,-3));

			pair P100 = Drawing("100", (2,-3));
			pair P101 = Drawing("101", (4,-3));
			pair P110 = Drawing("110", (6,-3));
			pair P111 = Drawing("111", (8,-3));

			label("$\vdots$", (-7,-3), dir(-90));
			label("$\vdots$", (-3,-3), dir(-90));
			label("$\vdots$", (3,-3), dir(-90));
			label("$\vdots$", (7,-3), dir(-90));

			draw(P01--P0--P00);
			draw(P11--P1--P10);
			draw(P0--P--P1);
			draw(P000--P00--P001);
			draw(P100--P10--P101);
			draw(P010--P01--P011);
			draw(P110--P11--P111);
		\end{asy}
	\end{center}

	\begin{enumerate}[(a)]
		\ii The maximal element $1_\Po$ is the empty string $\varnothing$.
		\ii $D = \{\text{all strings ending in $001$}\}$ is an example of a dense set.
		\ii No two elements of $\Po$ are compatible unless they are comparable.
	\end{enumerate}
\end{example}


Now, I can specify what it means to be ``generic''.
\begin{definition}
	A nonempty set $G \subseteq \Po$ is a \vocab{filter} if
	\begin{enumerate}[(a)]
		\ii The set $G$ is upwards-closed:
		$\forall p \in G (\forall q \ge p) (q \in G)$.
		\ii Any pair of elements in $G$ is compatible.
	\end{enumerate}
	We say $G$ is \vocab{$M$-generic} if for all $D$ which are \emph{in the model $M$},
	if $D$ is dense then $G \cap D \neq \varnothing$.
\end{definition}
\begin{ques}
	Show that if $G$ is a filter then $1_\Po \in G$.
\end{ques}
\begin{example}[Generic Filters on the Infinite Binary Tree]
	Let $\Po = 2^{<\omega}$.
	The generic filters on $\Po$ are sets of the following form:
	\[ \left\{ 0,\; b_1,\; b_1b_2,\; b_1b_2b_3,\; \dots \right\}. \]
	So every generic filter on $\Po$ correspond to a binary number $b = 0.b_1b_2b_3\dots$.

	It is harder to describe which reals correspond to generic filters,
	but they should really ``look random''.
	For example, the set of strings ending in $011$ is dense,
	so one should expect ``$011$'' to appear inside $b$,
	and more generally that $b$ should contain every binary string.
	So one would expect the binary expansion of $\pi-3$ might correspond to a generic,
	but not something like $0.010101\dots$.
	That's why we call them ``generic''.
\end{example}

\begin{center}
	\begin{asy}
		size(8cm);
		pair P = Drawing("\varnothing", red, (0,4), red, dir(90));
		pair P0 = Drawing("0", red, (-5,2), red, 1.5*dir(90));
		pair P1 = Drawing("1", (5,2),  1.5*dir(90));
		pair P00 = Drawing("00", (-7,0), 1.4*dir(120));
		pair P01 = Drawing("01", red, (-3,0), red, 1.4*dir(60));
		pair P10 = Drawing("10", (3,0),  1.4*dir(120));
		pair P11 = Drawing("11", (7,0),  1.4*dir(60));

		pair P000 = Drawing("000", (-8,-3));
		pair P001 = Drawing("001", (-6,-3));
		pair P010 = Drawing("010", red, (-4,-3), red);
		pair P011 = Drawing("011", (-2,-3));

		pair P100 = Drawing("100", (2,-3));
		pair P101 = Drawing("101", (4,-3));
		pair P110 = Drawing("110", (6,-3));
		pair P111 = Drawing("111", (8,-3));

		draw(P01--P0--P00);
		draw(P11--P1--P10);
		draw(P0--P--P1);
		draw(P000--P00--P001);
		draw(P100--P10--P101);
		draw(P010--P01--P011);
		draw(P110--P11--P111);

		draw(P--P0--P01--P010--(P010+2*dir(-90)), red+1.4);
		MP("G", P010+2*dir(-90), dir(-90), red);
	\end{asy}
\end{center}

\begin{exercise}
	Verify that these are every generic filter $2^{<\omega}$ has the form above.
	Show that conversely, a binary number gives a filter, but it need not be generic.
\end{exercise}

Notice that if $p \ge q$, then the sentence $q \in G$ tells us more information than the sentence $p \in G$.
In that sense $q$ is a \emph{stronger} condition.
In another sense $1_\Po$ is the weakest possible condition,
because it tells us nothing about $G$; we always have $1_\Po \in G$
since $G$ is upwards closed.

\section{More Properties of Posets}
We had better make sure that generic filters exist.
In fact this is kind of tricky, but for countable models it works:
\begin{lemma}[Rasiowa-Sikorski Lemma]
	Suppose $M$ is a \emph{countable} transitive model of $\ZFC$
	and $\Po$ is a partial order.
	Then there exists an $M$-generic filter $G$.
\end{lemma}
\begin{proof}
	Since $M$ is countable, there are only countably many dense sets (they live in $M$!),
	say \[ D_1, D_2, \ldots, D_n, \ldots \in M. \]
	Using Choice,
	let $p_1 \in D_1$, and then let $p_2 \le p_1$ such that $p_2 \in D_2$
	(this is possible since $D_2$ is dense), and so on.
	In this way we can inductively exhibit a chain
	\[ p_1 \ge p_2 \ge p_3 \ge \dots \]
	with $p_i \in D_i$ for every $i$.

	Hence, we want to generate a filter from the $\{p_i\}$.
	Just take the upwards closure -- let $G$ be the set of $q \in \Po$ such that $q \ge p_n$ for some $n$.
	By construction, $G$ is a filter (this is actually trivial).
	Moreover, $G$ intersects all the dense sets by construction.
	\todo{problem?}
\end{proof}
Fortunately, for breaking $\CH$ we would want $M$ to be countable anyways.
% This is really just the proof of the Baire category theorem.

The other thing we want to do to make sure we're on the right track is guarantee
that a generic set $G$ is not actually in $M$.
(Analogy: $\ZZ[3]$ is a really stupid extension.)
The condition that guarantees this is:

\begin{definition}
	A partial order $\Po$ is \vocab{splitting} if
	for all $p \in \Po$, there exists $q,r \le p$
	such that $q \perp r$.
\end{definition}
\begin{example}[Infinite Binary Tree is (Very) Splitting]
	The infinite binary tree is about as splitting as you can get.
	Given $p \in 2^{<\omega}$, just consider the two elements right under it.
\end{example}

\begin{lemma}[Splitting Posets Omit Generic Sets]
	Suppose $\Po$ is splitting.  Then if $F \subseteq \Po$ is a filter
	such that $F \in M$, then $\Po \setminus F$ is dense.
	In particular, if $G \subseteq \Po$ is generic, then $G \notin M$.
\end{lemma}
\begin{proof}
	Consider $p \notin \Po \setminus F \iff p \in F$.
	Then there exists $q, r \le p$ which are not compatible.
	Since $F$ is a filter it cannot contain both;
	we must have one of them outside $F$, say $q$.
	Hence every element of $p \in \Po \setminus (\Po \setminus F)$
	has an element $q \le p$ in $\Po \setminus F$.
	That's enough to prove $\Po \setminus F$ is dense.
	\begin{ques}
		Deduce the last assertion of the lemma about generic $G$. \qedhere
	\end{ques}
\end{proof}

\section{Names, and the Generic Extension}
We now define the \emph{names} associated to a poset $\Po$.

\begin{definition}
	Suppose $M$ is a transitive model of $\ZFC$, $\Po = (\Po, \le) \in M$ is a partial order.
	We define the hierarchy of \vocab{$\Po$-names} recursively by
	\begin{align*}
		\Name_0 &= \varnothing \\
		\Name_{\alpha+1} &= \PP(\Name_\alpha \times \Po) \\
		\Name_{\lambda} &= \bigcup_{\alpha < \lambda} \Name_\alpha.
	\end{align*}
	Finally, $\Name = \bigcup_\alpha \Name_\alpha$ denote the class of all $\Po$-names.
	% For $\tau \in \Name$, let $\nrank(\tau)$ be the least $\alpha$ such that $\tau \in \Name_\alpha$.
\end{definition}
(These $\Name_\alpha$'s are the analog of the $V_\alpha$'s:
each $\Name_\alpha$ is just the set of all names with rank $\le \alpha$.)

\begin{definition}
	For a filter $G$, we define the \vocab{interpretation} of $\tau$ by $G$,
	denote $\tau^G$, using the transfinite recursion
	\[ \tau^G
		= \left\{ \sigma^G
		\mid \left<\sigma, p\right> \in \tau
		\text{ and } p \in G\right\}. \]
	We then define the model
	\[ M[G] = \left\{ \tau^G \mid \tau \in \Name^M \right\}. \]
	In words, $M[G]$ is the interpretation of all the possible $\Po$-names
	(as computed by $M$).
\end{definition}

\textbf{You should think of a $\Po$-name as a ``fuzzy set''.}
Here's the idea.
Ordinary sets are collections of ordinary sets,
so fuzzy sets should be collections of fuzzy sets.
These fuzzy sets can be thought of like the Ghosts of Christmases yet to come:
they represent things that might be, rather than things that are certain.
In other words, they represent the possible futures of $M[G]$ for various choices of $G$.

Every fuzzy set has an element $p \in \Po$ pinned to it.
When it comes time to pass judgment,
we pick a generic $G$ and filter through the universe of $\Po$-names.
The fuzzy sets with an element of $G$ attached to it materialize into the real world,
while the fuzzy sets with elements outside of $G$ fade from existence.
The result is $M[G]$.

\begin{example}[First Few Levels of the Name Hierarchy]
	Let us compute
	\begin{align*}
		\Name_0 &= \varnothing \\
		\Name_1 &= \PP(\varnothing \times \Po) \\
		&= \{\varnothing\} \\
		\Name_2 &= \PP(\{\varnothing\} \times \Po) \\
		&= \PP\left( \left\{ 
			\left<\varnothing, p\right>
			\mid p \in \Po
		\right\} \right).
	\end{align*}
\end{example}
Compare the corresponding von Neuman universe.
\[ V_0 = \varnothing, \; V_1 = \{\varnothing\}, \;
V_2 = \left\{ \varnothing, \left\{ \varnothing \right\} \right\}. \]

\begin{example}[Example of an Interpretation]
	As we said earlier, $\Name_1 = \{\varnothing\}$.
	Now suppose
	\[ \tau =
		\left\{
			\left<\varnothing, p_1\right>,
			\left<\varnothing, p_2\right>,
			\dots
			\left<\varnothing, p_n\right>
		\right\} 
		\in \Name_2. \]
	Then 
	\[
		\tau^G
		= \left\{ \varnothing \mid
		\left<\varnothing, p\right> \in \tau \text{ and } p \in G\right\}
		=
		\begin{cases}
			\{\varnothing\} & \text{if some } p_i \in G \\
			\varnothing & \text{otherwise}.
		\end{cases}
	\]
	In particular, remembering that $G$ is nonempty we see that
	\[ \left\{ \tau^G \mid \tau \in \Name_2 \right\} = V_2^M. \]
	In fact, this holds for any natural number $n$, not just $2$.
\end{example}
So, $M[G]$ and $M$ agree on finite sets.

Now, we want to make sure $M[G]$ contains the elements of $M$.
To do this, we take advantage of the fact that $1_\Po$ must be in $G$, and define
for every $x \in M$ the set
\[ \check x = \left\{ \left<\check y, 1_\Po\right> \mid y \in x \right\} \]
by transfinite recursion.
Basically, $\check x$ is just a copy of $x$ where we add check marks and tag every element with $1_\Po$.

\begin{example}
	Compute $\check 0 = 0$ and $\check 1 = \left\{ \left<\check 0, 1_\Po\right> \right\}$.
	Thus \[ (\check 0)^G = 0 \quad\text{and}\quad (\check 1)^G = 1. \]
\end{example}
\begin{ques}
	Show that in general, $(\check x)^G = x$.
	(Rank induction.)
\end{ques}

However, we'd also like to cause $G$ to be in $M[G]$.
In fact, we can write down the name exactly:
\[ \dot G = \left\{ \left<\check p, p\right> \mid p \in \Po \right\}. \]
\begin{ques}
	Show that $(\dot G)^G = G$.
\end{ques}
\begin{ques}
	Verify that $M[G]$ is transitive:
	that is, if $\sigma^G \in \tau^G \in M[G]$, show that $\sigma^G \in M[G]$.
	(This is offensively easy.)
\end{ques}

In summary,
\begin{moral}
	$M[G]$ is a transitive model extending $M$ (it contains $G$).
\end{moral}

Moreover, it is reasonably well-behaved even if $G$ is just a filter.
Let's see what we can get off the bat.
\begin{lemma}[Properties Obtained from Filters]
	Let $M$ be a transitive model of $\ZFC$.
	If $G$ is a filter, then $M[G]$ is transitive
	and satisfies $\Extensionality$, $\Foundation$, 
	$\EmptySet$, $\Infinity$, $\Pairing$, and $\Union$.
\end{lemma}

This leaves $\PowerSet$, $\Replacement$, and Choice.
\begin{proof}
	Hence, we get $\Extensionality$ and $\Foundation$ for free.
	Then $\Infinity$ and $\EmptySet$ follows from $M \subseteq M[G]$.

	For $\Pairing$, suppose $\sigma_1^G, \sigma_2^G \in M[G]$.
	Then
	\[ \sigma = 
		\left\{ \left<\sigma_1, 1_\Po\right>, \left<\sigma_2, 1_\Po\right> \right\}
	\]
	works satisfies $\sigma^G = \{\sigma_1, \sigma_2\}$.
	(Note that we used $M \vDash \Pairing$.)
	$\Union$ is left as a problem, which you are encouraged to try now.
\end{proof}
Up to here, we don't need to know anything about when a sentence is true in $M[G]$;
all we had to do was contrive some names like $\check x$ or
$\left\{ \left<\sigma_1, 1_\Po\right>, \left<\sigma_2, 1_\Po\right> \right\}$
to get the facts we wanted.
But for the remaining axioms, we \emph{are} going to need this extra power
are true in $M[G]$.
For this, we have to introduce the Fundamental Theorem of Forcing.

\section{Fundamental Theorem of Forcing}
The model $M$ unfortunately has no idea what $G$ might be,
only that it is some generic filter.\footnote{%
	You might say this is a good thing, here's why.
	We're trying to show that $\neg \CH$ is consistent with $\ZFC$,
	and we've started with a model $M$ of the real universe $V$.
	But for all we know $\CH$ might be true in $V$ (what if $V=L$?),
	in which case it would also be true of $M$.

	Nonetheless, we boldly construct $M[G]$ an extension of the model $M$.
	In order for it to behave differently from $M$, it has to be out of reach of $M$.
	Conversely, if $M$ could compute everything about $M[G]$,
	then $M[G]$ would have to conform to $M$'s beliefs.

	That's why we worked so hard to make sure $G \in M[G]$ but $G \notin M$.
}
Nonetheless, we are going to define a relation $\Vdash$, called the \emph{forcing} relation.
Roughly, we are going to write
\[ p \Vdash \varphi(\sigma_1, \dots, \sigma_n) \]
where $p \in \Po$, $\sigma_1, \dots, \sigma_n \in M[G]$, if and only if the following holds:
\begin{quote}
	For \emph{any} generic $G$,
	if $p \in G$,
	then $M[G] \vDash \varphi(\sigma_1^G, \dots, \sigma_n^G)$.
\end{quote}
Note that $\Vdash$ is defined without reference to $G$:
it is something that $M$ can see.
We say $p$ \vocab{forces} the sentences $\varphi(\sigma_1, \dots, \sigma_n)$.
And miraculously, we can define this relation in such a way that the converse is true:
\emph{a sentence holds if and only if some $p$ forces it}.


\begin{theorem}
	[Fundamental Theorem of Forcing]
	Suppose $M$ is a transitive model of ZF.
	Let $\Po \in M$ be a poset, and $G \subseteq \PP$ is an $M$-generic filter.
	Then,
	\begin{enumerate}[(1)]
		\ii Consider $\sigma_1, \dots, \sigma_n \in \Name^M$,
		Then
		\[ M[G] \vDash \varphi[\sigma_1^G, \dots, \sigma_n^G] \]
		if and only if there exists a condition $p \in G$
		such that $p$ \emph{forces} the sentence $\varphi(\sigma_1, \dots, \sigma_n)$.
		We denote this by $p \Vdash \varphi(\sigma_1, \dots, \sigma_n)$.
		\ii This forcing relation is (uniformly) definable in $M$.
	\end{enumerate}
\end{theorem}

I'll tell you how the definition works in the following.

\section{(Optional) Defining the Relation}
Here's how we're going to go.
We'll define the most generous condition possible such that
the forcing works in one direction ($p \vDash \varphi(\sigma_1, \dots, \sigma_n)$ means
$M[G] \vDash \varphi[\sigma_1^G, \dots, \sigma_n^G]$).
We will then cross our fingers that the converse also works.

We proceed by induction on the formula complexity.
It turns out in this case that the atomic formula (base cases)
are hardest and themselves require induction on ranks.

For some motivation, let's consider how we should define $p \Vdash \tau_1 \in \tau_2$ given that we've already defined $p \vDash \tau_1 = \tau_2$.
We need to ensure this holds iff
\[ \forall \text{$M$-generic $G$ with $p \in G$}:
	\ M[G] \vDash \tau_1^G \in \tau_2^G. \]
So it suffices to ensure that any generic $G \ni p$ hits a condition $q$ which forces $\tau_1^G$ to \emph{equal} a member $\tau^G$ of $\tau_2^G$.
In other words, we want to choose the definition of $p \Vdash \tau_1 \in \tau_2$ to hold if and only if
\[
	\left\{ q \in \Po
	\mid \exists \left<\tau, r\right> \in \tau_2 
	\left( q \le r \land q \Vdash(\tau=\tau_1) \right)
	\right\}
\]
is dense below in $p$.
In other words, if the set is dense, then the generic must hit $q$, so it must hit $r$, meaning that $\left<\tau_r\right> \in \tau_2$ will get interpreted such that $\tau^G \in \tau_2^G$, and moreover the $q \in G$ will force $\tau_1 = \tau$.

Now let's write down the definition\dots
In what follows, the $\Vdash$ omits the $M$ and $\Po$.
\begin{definition}
	Let $M$ be a countable transitive model of ZFC.
	Let $\Po \in M$ be a partial order.
	For $p \in \Po$ and $\varphi(\sigma_1, \dots, \sigma_n)$ a formula in LST, we write $\tau \Vdash \varphi(\sigma_1, \dots, \sigma_n)$ to mean the following, defined by induction on formula complexity plus rank.
	\begin{enumerate}[(1)]
		\ii $p \Vdash \tau_1 = \tau_2$ means
		\begin{enumerate}[(i)]
			\ii For all $\left<\sigma_1, q_1\right> \in \tau_1$ the set
			\[ D_{\sigma_1, q_1}
				\defeq
				\left\{ r \mid
				r \le q_1 \lthen \exists \left<\sigma_2, q_2\right> \in \tau_2 \left( r \le q_2 \land r \Vdash (\sigma_1 = \sigma_2) \right)\right\}.
			\]
			is dense in $p$.
			(This encodes ``$\tau_1 \subseteq \tau_2$''.)
			\ii For all $\left<\sigma_2, q_2\right> \in \tau_2$,
			the set $D_{\sigma_2, q_2}$ defined similarly is dense below $p$.
		\end{enumerate}
		\ii $p \Vdash \tau_1 \in \tau_2$ means
		\[
		\left\{ q \in \Po
		\mid \exists \left<\tau, r\right> \in \tau_2 
		\left( q \le r \land q \Vdash(\tau=\tau_1) \right)
		\right\} \]
		is dense below $p$.
		\ii $p \Vdash \varphi \land \psi$ means $p \Vdash \varphi$ and $p \Vdash \psi$.
		\ii $p \Vdash \neg \varphi$ means $\forall q \le p$, $q \not\Vdash \varphi$.
		\ii $p \Vdash \exists x \varphi(x, \sigma_1, \dots, \sigma_n)$ means that the set
		\[
			\left\{ q \mid \exists \tau
				\left( q \Vdash \varphi(\tau, \sigma_1, \dots, \sigma_n \right)
			\right\}
		\]
		is dense below $p$.
	\end{enumerate}
\end{definition}
This is definable in $M$!
All we've referred to is $\Po$ and names, which are in $M$.
(Note that being dense is definable.)
Actually, in parts (3) through (5) of the definition above,
we use induction on formula complexity.
But in the atomic cases (1) and (2) we are doing induction on the ranks of the names.

So, the construction above gives us one direction (I've omitted tons of details, but\dots).

Now, how do we get the converse: that a sentence is true if and only if something forces it?
Well, by induction, we can actually show the following result:
\begin{lemma}[Consistency and Persistence]
	We have
	\begin{enumerate}[(1)]
		\ii (Consistency) If $p \Vdash \varphi$ and $q \le p$ then $q \Vdash \varphi$.
		\ii (Persistence) If $\left\{ q \mid q \Vdash \varphi \right\}$
		is dense below $p$ then $p \Vdash \varphi$.
	\end{enumerate}
\end{lemma}
You can prove both of these by induction on formula complexity.
From this it also follows that
\begin{corollary}[Completeness]
	The set $\left\{ p \mid p \Vdash \varphi \text{ or } p \Vdash \neg\varphi \right\}$
	is dense.
\end{corollary}
\begin{proof}
	We claim that whenever $p \not\Vdash \varphi$ then
	for some $\ol p \le p$ we have $\ol p \Vdash \neg\varphi$;
	this will establish the corollary.

	By the contrapositive of the previous lemma,
	$\{q \mid q \Vdash \varphi\}$ is not dense below $p$,
	meaning for some $\ol p \le p$, every $q \le \ol p$ gives $q \not\Vdash \varphi$.
	By the definition of $p \vDash \neg\varphi$,
	we have $\ol p \vDash \neg\varphi$.
\end{proof}
And this gives the converse: the $M$-generic $G$ has to hit some condition
that passes judgment, one way or the other.
This completes the proof of the Fundamental Theorem.

\section{The Remaining Axioms}
\begin{theorem}[The Generic Extension Satisfies $\ZFC$]
	Suppose $M$ is a transitive model of $\ZFC$.
	Let $\Po \in M$ be a poset, and $G \subseteq \PP$ is an $M$-generic filter.
	Then \[ M[G] \vDash \ZFC. \]
\end{theorem}
\begin{proof}
	We'll just do $\Comprehension$, as the other remaining axioms are similar.
	
	Suppose $\sigma^G, \sigma_1^G, \dots, \sigma_n^G \in M[G]$
	are a set and parameters, and
	$\varphi(x,x_1, \dots, x_n)$ is an LST formula.
	We want to show that the set
	\[ A = \left\{ 
		x \in \sigma^G \mid M[G] \vDash \varphi[x, \sigma_1^G, \dots, \sigma_n^G]
	\right\} \]
	is in $M[G]$; i.e.\ it is the interpretation of some name.

	Note that every element of $\sigma^G$ is of the form $\rho^G$
	for some $\rho \in \dom(\sigma)$ (a bit of abuse here,
	$\sigma$ is a bunch of pairs of names and $p$'s,
	and the domain is just the set of names).
	So by the Fundamental Theorem of Forcing, we may write
	\[ A = 
		\left\{ \rho^G \mid \rho \in \dom(\sigma)
			\text{ and }
			\exists p \in G
			\left( p \Vdash \rho \in \sigma
			\land \varphi(\rho, \sigma_1, \dots, \sigma_n)
			\right)
		\right\}.
	\]
	To show $A \in M[G]$ we have to write down a $\tau$
	such that the name $\tau^G$ coincides with $A$.
	We claim that
	\[
		\tau
		=
		\left\{ \left<\rho, p\right>
			\in \dom(\sigma) \times \Po \mid
			p \Vdash 
			\land \varphi(\rho, \sigma_1, \dots, \sigma_n)
		\right\}
	\]
	is the correct choice.
	It's actually clear that $\tau^G = A$ by construction;
	the ``content'' is showing that $\tau$ is in actually a name of $M$,
	which follows from $M \vDash \Comprehension$.

	So really, the point of the Fundamental Theorem of Forcing
	is just to let us write down this $\tau$;
	it lets us show that $\tau$ is in $\Name^M$
	without actually referencing $G$.
\end{proof}


\section\problemhead
\begin{problem}
	For a filter $G$ and $M$ a transitive model of $\ZFC$,
	show that $M[G] \vDash \Union$.
\end{problem}

%\begin{exercise}
%	Show that $\rank \sigma^G \le \nrank(\sigma)$ for any $\sigma \in \Name^M$.
%\end{exercise}

%\begin{exercise}
%	Check that
%	\begin{enumerate}[(1)]
%		\ii $(\check x)^G = x$.
%		\ii $(\dot G)^G = G$.
%	\end{enumerate}
%\end{exercise}



\chapter{The Failure of the Continuum Hypothesis}
We now use the technique of forcing to break the Contiuum Hypothesis by choosing a good poset $\Po$.

\section{Forcing $V \neq L$ is really easy}
As a small aside, to check we're on the right track we show the following result.

\begin{theorem}[$V \ne L$]
	Let $M$ be a countable transitive model of $\ZFC$.
	Let $\Po \in M$ be \emph{any} splitting poset,
	and let $G \subseteq \Po$ be $M$-generic.
	Then $M[G] \vDash (V \neq L)$.
\end{theorem}
\begin{proof}
	Since $L$ has a $\Sigma_1$ definition,
	we have \[ L^{M[G]} = L^M \subseteq M \subsetneq M[G] \]
	where the last part follows from $G \notin M[G]$.
\end{proof}

Thus $M[G] \vDash \ZFC + (V \ne L)$ for any splitting poset $\Po$,
and we are one step closer to breaking $\CH$.

\section{Adding in Reals}
Starting with a \emph{countable} transitive model $M$.

We want to choose $\Po \in M$ such that $(\aleph_2)^M$ many real numbers appear,
and then worry about cardinal collapse later.

Recall the earlier situation where we set $\Po$ to be the infinite complete binary tree; its nodes can be thought of as partial functions $n \to 2$ where $n < \omega$.
Then $G$ itself is a path down this tree; i.e.\ it can be encoded as a total function $G : \omega \to 2$,
and corresponds to a real number.

\begin{center}
	\begin{asy}
		size(8cm);
		pair P = Drawing("\varnothing", red, (0,4), red, dir(90));
		pair P0 = Drawing("0", red, (-5,2), red, 1.5*dir(90));
		pair P1 = Drawing("1", (5,2),  1.5*dir(90));
		pair P00 = Drawing("00", (-7,0), 1.4*dir(120));
		pair P01 = Drawing("01", red, (-3,0), red, 1.4*dir(60));
		pair P10 = Drawing("10", (3,0),  1.4*dir(120));
		pair P11 = Drawing("11", (7,0),  1.4*dir(60));

		pair P000 = Drawing("000", (-8,-3));
		pair P001 = Drawing("001", (-6,-3));
		pair P010 = Drawing("010", red, (-4,-3), red);
		pair P011 = Drawing("011", (-2,-3));

		pair P100 = Drawing("100", (2,-3));
		pair P101 = Drawing("101", (4,-3));
		pair P110 = Drawing("110", (6,-3));
		pair P111 = Drawing("111", (8,-3));

		draw(P01--P0--P00);
		draw(P11--P1--P10);
		draw(P0--P--P1);
		draw(P000--P00--P001);
		draw(P100--P10--P101);
		draw(P010--P01--P011);
		draw(P110--P11--P111);

		draw(P--P0--P01--P010--(P010+2*dir(-90)), red+1.4);
		MP("G", P010+2*dir(-90), dir(-90), red);
	\end{asy}
\end{center}

We want to do something similar, but with $\omega_2$ many real numbers instead of just one.
In light of this, consider in $M$ the following poset:
\[
	\Po = 
	\opname{Add} \left( \omega_2, \omega \right)
	\defeq
	\left( 
	\left\{ p : \omega_2 \times \omega \to 2,
		\dom(p) < \omega
	\right\},
	\supseteq
	\right).
\]
These elements (conditions) are ``partial functions'':
we take some finite subset of $\omega \times \omega_2$ and map it into $2=\{0,1\}$.
Moreover, we say $p \le q$ if $\dom(p) \supseteq \dom(q)$ and the two functions agree over $\dom(q)$.
\begin{ques}
	What is $1_\Po$ here?
\end{ques}

\begin{exercise}
	Show that a generic $G$ can be encoded as a function $\omega_2 \times \omega \to 2$.
\end{exercise}

%Let $G \subseteq \opname{Add}(\omega_2, \omega)$ be an $M$-generic.
%We claim that, like in the binary case, $G$ can be encoded as a function $\omega_2 \times \omega \to 2$.
%To see this, consider $\alpha \in \omega_2$ and $n \in \omega$; we have the dense set
%\[ D_{\alpha, n}
%	= \left\{ p \in \opname{Add}(\omega_2, \omega)
%	\mid (\alpha, n) \in \dom(p) \right\}
%\]
%(this is obviously dense, given any $p$ add in $(\alpha, n)$ if it's not in there already).
%So $G$ hits this dense set, meaning that for every $(\alpha, n)$ there's a function in $G$ which defines it.
%Using the fact that $G$ is upwards closed and a filter, we may as before we may interpret $G$ as a function $\omega_2 \times \omega \to 2$.

\begin{lemma}[$G$ encodes distinct real numbers]
	For $\alpha \in \omega_2$ define
	\[ G_\alpha = \left\{ n \mid G\left( \alpha,n \right) = 0 \right\} \in \PP(\NN). \]
	Then $G_\alpha \neq G_\beta$ for any $\alpha \neq \beta$.
\end{lemma}
\begin{proof}
	We claim that the set
	\[ D = \left\{ q \mid \exists n \in \omega :
		q\left( \alpha, n \right) \neq q\left( \beta, n \right)
		\text{ are both defined}
	\right\} \]
	is dense.
	\begin{ques}
		Check this.
		(Use the fact that the domains are all finite.)
	\end{ques}
%	This is pretty easy to see.
%	Consider $p \in \opname{Add}(\omega_2, \omega)$.
%	Then you can find an $n$ such that
%	neither $(\alpha, n)$ nor $(\beta, n)$ is defined,
%	just because $\dom(p)$ is finite.
%	Then you make $p'$ as $p$ plus $p'( (\alpha, n) ) = 1$
%	and $p'( (\beta, n) ) = 0$.
%	Hence the set is dense.

	Since $G$ is an $M$-generic it hits this dense set $D$.
	Hence $G_\alpha \neq G_\beta$.
\end{proof}

Since $G \in M[G]$ and $M[G] \vDash \ZFC$,
it follows that each $G_\alpha$ is in $M[G]$.
So there are at least $\aleph_2^M$ real numbers in $M$.
We are done once we can show there is no cardinal collapse.

\section{The Countable Chain Condition}
It remains to show that with $\Po = \opname{Add}(\omega, \omega_2)$, we have that
\[ \aleph_2^{M[G]} = \aleph_2^M. \]
In that case, since $M[G]$ will have $\aleph_2^M = \aleph_2^{M[G]}$ many reals, we will be done.

To do this, we'll rely on the following combinatorial property of $\Po$:

\begin{definition}
	We say that $A \subset \mathcal P$ is a \vocab{strong antichain}
	if for any distinct $p$ and $q$ in $A$, we have $p \perp q$.
\end{definition}
\begin{example}[Example of an Antichain]
	In the infinite binary tree, 
	the set $A = \{00, 01, 10, 11\}$ is a strong antichain
	(in fact maximal by inclusion).
\end{example}
This is stronger than the notion of ``antichain'' than you might be used to!\footnote{%
	In the context of forcing, some authors use ``antichain'' to refer to ``strong antichain''.
	I think this is lame.}
We don't merely require that every two elements are incomparable,
but that they are in fact \emph{incompatible}.
\begin{ques}
	Draw a finite poset and an antichain of it which is not strong.
\end{ques}

\begin{definition}
	A poset $\Po$ has the \vocab{$\kappa$-chain condition}
	(where $\kappa$ is a cardinal) if all strong antichains
	in $\Po$ have size less than $\kappa$.
	The special case $\kappa = \aleph_1$ is called the \vocab{countable chain condition},
	because it implies that every strong antichain is countable.
\end{definition}

We are going to show that if the poset has the $\kappa$-chain condition
then it preserves all cardinals greater than $\kappa$.
% or was it > \kappa?
In particular, the countable chain condition will show that $\Po$ preserves all the cardinals.
Then, we'll show that $\opname{Add}(\omega, \omega_2)$ does indeed have this property.
This will complete the proof.

We isolate the following lemma.
\begin{lemma}[Possible Values Argument]
	Suppose $M$ is a transitive model of $\ZFC$ and $\Po$ is a partial order
	such that $\Po$ has the $\kappa$-chain condition in $M$.
	Let $X,Y \in M$ and let $f: X \to Y$
	be some function in $M[G]$, but $f \notin M$.

	Then there exists a function $F \in M$, with $F: X \to \PP(Y)$ and such that
	for any $x \in X$,
	\[ f(x) \in F(x) \quad\text{and}\quad \left\lvert F(x) \right\rvert^M < \kappa. \]
\end{lemma}
What this is saying is that if $f$ is some new function that's generated,
$M$ is still able to pin down the values of $f$ to at most $\kappa$ many values.

\begin{proof}
	The idea behind the proof is easy: any possible value of $f$ gives us some condition in
	the poset $\Po$ which forces it.
	Since distinct values must have incompatible conditions,
	the $\kappa$-chain condition guarantees
	there are at most $\kappa$ such values.

	Here are the details.
	Let $\dot f$, $\check X$, $\check Y$ be names for $f$, $X$, $Y$.
	Start with a condition $p$ such that $p$ forces the sentence
	\[ \text{``$\dot f$ is a function from $\check X$ to $\check Y$''}. \]
	We'll work just below here.

	For each $x \in X$, we can consider (using the Axiom of Choice) a maximal antichain $A(x)$
	of incompatible conditions $q \le p$ which forces $f(x)$ to equal some value $y \in Y$.
	Then, we let $F(x)$ collect all the resulting $y$-values.
	These are all possible values, and there are less than $\kappa$ of them.
\end{proof}

\section{Preserving Cardinals}
\begin{definition}
	For $M$ a transitive model of ZFC and $\Po \in M$ a poset,
	we say $\Po$ \vocab{preserves cardinals} if
	$\forall G \subseteq \Po$ an $M$-generic,
	the model $M$ and $M[G]$ agree on the sentence ``$\kappa$ is a cardinal'' for every $\kappa$.

	In the same way we will talk about $\Po$ preserving cofinalities, et cetera.
\end{definition}

\todo{write out this exercise}
\begin{exercise}
	Let $M$ be a transitive model of ZFC.
	Let $\Po \in M$ be a poset.
	Show that the following are equivalent for each $\lambda$:
	\begin{enumerate}[(1)]
		\ii $\Po$ preserves cofinalities less than or equal to $\lambda$.
		\ii $\Po$ preserves regular cardinals less than or equal to $\lambda$.
	\end{enumerate}
	Moreover the same holds if we replace ``less than or equal to''
	by ``greater than or equal to''.
\end{exercise}
Thus, to show that $\Po$ preserves cardinality and cofinalities it suffices to show that $\Po$ preserves regularity.

\begin{theorem}
	Suppose $M$ is a transitive model of ZFC, and $\Po \in M$ is a poset.
	Suppose $M$ satisfies the sentence ``$\Po$ has the $\kappa$ chain condition and $\kappa$ is regular''.
	Then $\Po$ preserves cardinals and cofinalities greater than or equal to $\kappa$.
\end{theorem}
\begin{proof}
	It suffices to show that $\Po$ preserves regularity greater than or equal to $\kappa$.
	Consider $\lambda > \kappa$ which is regular in $M$,
	and suppose for contradiction that $\lambda$ is not regular in $M[G]$.
	That's the same as saying that there is a function $f \in M[G]$,
	$f : \ol \lambda \to \lambda$ cofinal, with $\ol \lambda < \lambda$.
	Then by the Possible Values Argument,
	there exists a function $F \in M$ from $\ol \lambda \to \PP(\lambda)$
	such that $f(\alpha) \in F(\alpha)$ and $\left\lvert F(\alpha) \right\rvert^M < \kappa$
	for every $\alpha$.

	Now we work in $M$ again.
	Note for each $\alpha \in \ol\lambda$,
	$F(\alpha)$ is bounded in $\lambda$ since $\lambda$ is regular in $M$ and
	greater than $\left\lvert F(\alpha) \right\rvert$.
	Now look at the function $\ol \lambda \to \lambda$ in $M$ by just
	\[ \alpha \mapsto \cup F(\alpha) < \lambda. \]
	This is cofinal in $M$, contradiction.
\end{proof}

\subsection{Infinite Combinatorics}
In particular, if $\Po$ has the countable chain condition then $\Po$ preserves all the cardinals (and cofinalities).
Therefore, it remains to show that $\opname{Add}(\omega, \omega_2)$ satisfies the countable chain condition.
And this is going to be infinite combinatorics.

\begin{definition}
	Suppose $C$ is an uncountable collection of finite sets.
	$C$ is a \textbf{$\Delta$-system} if there exists a \textbf{root} $R$
	with the condition that for any distinct $X$ and $Y$
	in $C$, we have $X \cap Y = R$.
\end{definition}

\begin{lemma}
	[$\Delta$-System Lemma] Suppose $C$ is an uncountable collection of finite sets.
	Then $\exists \ol C \subseteq C$ such that
	\begin{enumerate}[(1)]
		\ii $\ol C$ is uncountable.
		\ii $\ol C$ is a $\Delta$-system.
	\end{enumerate}
\end{lemma}
\begin{proof}
	There exists an integer $n$ such that $C$ has uncountably many guys of length $n$.
	So we can throw away all the other sets, and just assume that all sets in $C$ have size $n$.

	We now proceed by induction on $n$.
	The base case $n=1$ is trivial, since we can just take $R = \varnothing$.
	For the inductive step we consider two cases.

	First, assume there exists an $a \in C$ contained in uncountably many $F \in C$.
	Throw away all the other guys.
	Then we can just delete $a$, and apply the inductive hypothesis.

	Now assume that for every $a$, only countably many members of $C$ have $a$ in them.
	We claim we can even get a $\ol C$ with $R = \varnothing$.
	First, pick $F_0 \in C$.
	It's straightforward to construct an $F_1$ such that $F_1 \cap F_0 = \varnothing$.
	And we can just construct $F_2, F_3, \dots$
\end{proof}

\begin{lemma}
	For all $\kappa$, $\opname{Add}(\omega, \kappa)$ satisfies the countable chain condition.
\end{lemma}
\begin{proof}
	Assume not. Let
	\[ \left\{ p_\alpha : \alpha < \omega_1 \right\} \]
	be an antichain.  Let
	\[ C = \left\{ \dom(p_\alpha) : \alpha < \omega_1 \right\}. \]
	Let $\ol C \subseteq C$ be such that $\ol C$ is uncountable, and $\ol C$ is a $\Delta$-system which root $R$.
	Then let
	\[ B = \left\{ p_\alpha : \dom(p_\alpha) \in R \right\}. \]
	Each $p_\alpha \in B$ is a function $p_\alpha : R \to \{0,1\}$,
	so there are two that are the same.
\end{proof}
\todo{blah blah blah}

\end{document}
