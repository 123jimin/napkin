\documentclass[11pt]{scrreprt}
\input{../../tex/preamble}
\def\asydir{}
\addbibresource{../../references.bib}
\renewcommand{\gim}{*}
\renewcommand{\yod}{**}
\renewcommand{\kurumi}{***}

\begin{document}
\title{The Structure Theorem}
\maketitle

\tableofcontents
\section{Blah}
\label{ex:product_ring}

\chapter{The PID structure theorem}
The main point of this chapter is to discuss a classification
theorem for finitely generated abelian groups.
This won't take long to do, and if you like you can read
just the first section and then move on.

However, since I'm here, I will go ahead and state the result as a
special case of the much more general \emph{structure theorem}.
Its corollaries include
\begin{itemize}
	\ii The classification theorem for finitely generated abelian groups,
	\ii The Jordan decomposition of a matrix from before,
	\ii Another canonical form for a matrix: ``rational canonical form''.
\end{itemize}

\section{Finitely generated abelian groups}
\begin{remark}
	We talk about abelian groups in what follows, but really the
	morally correct way to think about these structures is as $\ZZ$-modules.
\end{remark}
\begin{definition}
	An abelian group $G = (G,+)$ is \vocab{finitely generated}
	if it is finitely generated as a $\ZZ$-module.
	(That is, there exists a finite collection $b_1, \dots, b_m \in G$,
	such that every $x \in G$ can be written in the form
	$c_1b_1 + \dots + c_mb_m$ for some $c_1, \dots, c_m \in \ZZ$.)
\end{definition}
\begin{example}
	[Examples of finitely generated abelian groups]
	\listhack
	\begin{enumerate}[(a)]
		\ii $\ZZ$ is finitely generated (by $1$).
		\ii $\Zc n$ is finitely generated (by $1$).
		\ii $\ZZ^{\oplus 2}$ is finitely generated (by two elements $(1,0)$ and $(0,1)$).
		\ii $\ZZ^{\oplus 3} \oplus \Zc9 \oplus \Zc{2016}$ is
		finitely generated by five elements.
		\ii $\Zc3\oplus\Zc5$ is finitely generated by two elements.
	\end{enumerate}
\end{example}
\begin{exercise}
	In fact $\Zc3\oplus\Zc5$ is generated by \emph{one} element.
	What is it?0
\end{exercise}
You might notice that these examples are not very diverse.
That's because they are actually the only examples:
\begin{theorem}
	[Funadmental theorem of finitely generated abelian groups]
	Let $G$ be a finitely generated abelian group.
	Then there exists an integer $r$,
	prime powers $q_1$, \dots, $q_m$ (not necessarily distinct) such that
	\[
		G \cong \ZZ^{\oplus r} \oplus \Zc{q_1} \oplus \Zc{q_2} \oplus
		\dots \oplus \Zc{q_m}. \]
	This decomposition is unique up to permutation of $\Zc{q_i}$.
\end{theorem}
\begin{definition}
	The \vocab{rank} of a finitely generated abelian group $G$ is the integer $r$ above.
\end{definition}

Now, we could prove this theorem, but it is more interesting to go for the gold
and state and prove the entire structure theorem.

\section{Some ring theory prerequisites}
\prototype{$R = \ZZ$.}
Before I can state the main theorem, I need to define a few terms for UFD's,
which behave much like $\ZZ$:
\begin{moral}
	Our intuition from the case $R = \ZZ$ basically carries over verbatim.
\end{moral}
We don't even need to deal with prime ideals and can factor elements instead.

\begin{definition}
	If $R$ is a UFD, then $p \in R$ is a \vocab{prime element}
	if $(p)$ is a prime ideal and $p \neq 0$.
	For UFD's this is equivalent to the following property:
	if $p = xy$ then either $x$ or $y$ is a unit.
\end{definition}
So for example in $\ZZ$ the set of prime elements is $\{\pm2, \pm3, \pm5, \dots\}$.
Now, since $R$ is a UFD, every element $r$ factors into a product of prime elements
\[ r = u p_1^{e_1} p_2^{e_2} \dots p_m^{e_m} \]

\begin{definition}
	We say $r$ \vocab{divides} $s$ if $s = r'r$ for some $r' \in R$. This is written $r \mid s$.
\end{definition}
Also, $0$ is divisible by every element of $\ZZ$.
\begin{ques}
	Show that $r \mid s$ if and only if the exponent of each prime in $r$ is
	less than or equal to the corresponding exponent in $s$.
\end{ques}

Now, the case of interest is the even stronger case
when $R$ is a principal ideal domain.
\begin{proposition}
	[PID's are Noetherian UFD's]
	If $R$ is a PID, then it is Noetherian and also a UFD.
\end{proposition}
\begin{proof}
	The fact that $R$ is Noetherian is obvious.
	For $R$ to be a UFD we essentially repeat the proof over $\ZZ$,
	using the fact that $(a,b)$ is principal for any $a$ and $b$
	in order to extract GCD's.
\end{proof}

In this case, we have a Chinese remainder theorem for elements.
\begin{theorem}
	[Chinese remainder theorem for rings]
	Let $m$ and $n$ be relatively prime elements, meaning $(m) + (n) = (1)$.
	Then \[ R / (mn) \cong R/m \times R/n. \]
\end{theorem}
Here the ring product is as defined in \Cref{ex:product_ring}.
\begin{proof}
	This is the same as the proof of the usual Chinese remainder theorem.
	First, since $(m,n)=(1)$ we have $am+bn=1$ for some $a$ and $b$.
	Then we have a map
	\[ R/m \times R/n \to R/(mn) \quad\text{by}\quad
		(r,s) \mapsto r \cdot bn + s \cdot am. \]
	One can check that this map is well-defined and an isomorphism of rings.
	(Diligent readers invited to do so.)
\end{proof}

Finally, we need to introduce the concept of a Noetherian $R$-module.
\begin{definition}
	An $R$-module $M$ is \vocab{Noetherian}
	if it satisfies one of the two equivalent conditions:
	\begin{itemize}
		\ii Its submodules obey the ascending chain condition:
		there is no infinite sequence of modules $M_1 \subsetneq M_2 \subsetneq \dots$.
		\ii All submodules of $M$ (including $M$) are finitely generated.
	\end{itemize}
\end{definition}
This generalizes the notion of a Noetherian ring:
a Noetherian ring $R$ is one for which $R$ is Noetherian as an $R$-module.
\begin{ques}
	Satisfy yourself these two conditions are equivalent.
	(Copy the proof for rings.)
\end{ques}

\section{The structure theorem}
Our structure theorem takes two forms:
\begin{theorem}
	[Structure theorem, invariant form]
	Let $R$ be a PID and let $M$ be any finitely generated $R$-module. Then
	\[ M \cong \bigoplus_{i=1}^m R/s_i \]
	for some $s_i$ satisfying $s_1 \mid s_2 \mid \dots \mid s_m$.
	% These $s_i$ are unique up to multiplication by units.
\end{theorem}
\begin{corollary}
	[Structure theorem, primary form]
	Let $R$ be a PID and let $M$ be any finitely generated $R$-module. Then
	\[ M \cong R^{\oplus r}
		\oplus R/(q_1) \oplus R/(q_2) \oplus \dots \oplus R/(q_m) \]
	where $q_i = p_i^{e_i}$ for some prime element $p_i$ and integer $e_i \ge 1$.
	% The numbers $r$ and $q_i$ are unique up to permutation and multiplication by units.
\end{corollary}
\begin{proof}
	[Proof of corollary]
	Factoring each $s_i$ into prime factors (since $R$ is a UFD),
	then use the Chinese remainder theorem.
\end{proof}
\begin{remark}
	In both theorems the decomposition is unique up to
	permutations of the summands; good to know, but
	I won't prove this.
\end{remark}

\section{Reduction to maps of free $R$-modules}
The proof of the structure theorem proceeds in two main steps.
First, we reduce the problem to a \emph{linear algebra} problem
involving free $R$-modules $R^{\oplus d}$.
Once that's done, we just have to play with matrices;
this is done in the next section.

Suppose $M$ is finitely generated by $d$ elements.
Then there is a surjective map of $R$-modules
\[ R^{\oplus d} \surjto M \]
whose image on the basis of $R^{\oplus d}$ are the generators of $M$.
Let $K$ denote the kernel of this map.

We claim that $K$ is finitely generated as well.
To this end we prove that
\begin{lemma}[Direct sum of Noetherian modules is Noetherian]
	Let $M$ and $N$ be two Noetherian $R$-modules.
	Then the direct sum $M \oplus N$ is also a Noetherian $R$-module.
\end{lemma}
\begin{proof}
	Let $X_1 \subseteq X_2 \subseteq X_3 \subseteq \dots \subseteq M \oplus N$
	be an infinite chain of submodules; we show it stabilizes.
	Then, the chains
	\[ X_1 \cap M \subseteq X_2 \cap M \subseteq \dots
		\quad\text{and}\quad
		X_1 \cap N \subseteq X_2 \cap N \subseteq \dots \]
	must eventually stabilize.
	So the $X_i$ eventually stabilize.
\end{proof}
\begin{ques}
	Deduce that for $R$ a PID, $R^{\oplus d}$ is Noetherian.
\end{ques}
Hence $K$ is finitely generated as claimed.
So we can find another surjective $R^{\oplus f} \surjto K$.
Consequently, we have a composition
\begin{diagram}
	&& K && && \\
	R^{\oplus f} & \ruSurj(2,1) & \rTo_T & \rdInj(2,1)
		& R^{\oplus d} & \rSurj & M
\end{diagram}
Observe that $M$ is the \emph{cokernel} of the linear map $T$,
i.e.\ we have that
\[ M \cong R^{\oplus d} / \img(T). \]
So it suffices to understand the map $T$ well.

\section{Smith normal form}
The idea is now that we have reduced our problem to studying
linear maps $T : R^{\oplus m} \to R^{\oplus n}$,
which can be thought of as a generic matrix
\[ 
	T = \begin{pmatrix}
		a_{11} & \dots & a_{1m} \\
		\vdots & \ddots & \vdots \\
		a_{n1} & \dots & a_{nm}
	\end{pmatrix} \]
for the standard basis $e_1$, \dots, $e_m$ of $R^{\oplus m}$
and $f_1$, \dots, $f_n$ of $N$.

Of course, as you might expect it ought to be possible to change the
given basis of $T$ such that $T$ has a nicer matrix form.
We already saw this in \emph{Jordan form},
where we had a map $T : V \to V$ and changed the basis
so that $T$ was ``almost diagonal''.
This time, we have \emph{two} sets of bases we can change,
so we would hope to get a diagonal basis, or even better.

Before proceeding let's think about how we might edit the matrix:
what operations are permitted?  Here are some examples:
\begin{itemize}
	\ii Swapping rows and columns, which just corresponds
	to re-ordering the basis.
	\ii Adding a multiple of a column to another column.
	For example, if we add $3$ times the first column to the second column,
	this is equivalent to replacing the basis 
	\[ (e_1, e_2, e_3, \dots, e_m) \mapsto (e_1, e_2+3e_1, e_3, \dots, e_m). \]
	\ii Adding a multiple of a row to another row.
	One can see that adding $3$ times the first row to the second row,
	this is equivalent to replacing the basis 
	\[ (f_1, f_2, f_3, \dots, f_n) \mapsto (f_1-3f_2, f_2, f_3, \dots, f_n). \]
\end{itemize}
More generally,
\begin{moral}
	If $A$ is an invertible $n \times n$ matrix we can
	replace $T$ with $AT$.
\end{moral}
This corresponds to replacing 
\[ (f_1, \dots, f_n) \mapsto (A(f_1), \dots, A(f_n)) \]
(the investability condition just guarantees the latter is a basis).
Of course similarly we can replace $X$ with $XB$
where $B$ is an invertible $m \times m$ matrix;
this corresponds to 
\[ (e_1, \dots, e_m) \mapsto (B\inv(e_1), \dots, B\inv(e_m)) \]
Armed with this knowledge, we can now approach the following result.

\begin{theorem}
	[Smith normal form]
	Let $R$ be a PID.
	Let $M = R^{\oplus m}$ and $N = R^{\oplus n}$ be free $R$-modules
	and let $T : M \to N$ be a linear map.
	Set $k = \min(m,n)$.

	Then we can select a pair of new bases for $M$ and $N$ such that 
	$T$ has only diagonal entries $s_1$, $s_2$, \dots, $s_k$
	and $s_1 \mid s_2 \mid \dots \mid s_k$.
\end{theorem}
So if $m > n$, the matrix should take the form
\[
	\begin{pmatrix} 
		s_1 & 0 & 0 & 0 & \dots & 0 \\
		0 & s_2 & 0 & 0 & \dots & 0 \\
		\vdots & \vdots & \ddots & \vdots & \dots & \vdots \\
		0 & 0 & 0 & s_n & \dots & 0
	\end{pmatrix}.
\]
and similarly when $m \le n$.
\begin{ques}
	Show that Smith normal from implies the structure theorem.
\end{ques}

\begin{remark}
	Note that this is not a generalization of Jordan form.
	\begin{itemize}
		\ii In Jordan form we consider maps $T : V \to V$;
		note that the source and target space are the \emph{same},
		and we are considering one basis for the space $V$.
		\ii In Smith form the maps $T : M \to N$ are between
		\emph{different} modules, and we pick \emph{two} sets of bases
		(one for $M$ and one for $N$).
	\end{itemize}
\end{remark}

\begin{example}
	[Example of Smith normal form]
	To give a flavor of the idea of the proof,
	let's work through a concrete example with the following
	matrix with entries from $\ZZ$:
	\[ \begin{pmatrix} 
			18 & 46 \\
			14 & 36
		\end{pmatrix}.  \]
	The GCD of all the entries is $2$, and so motivated by this,
	we perform the \textbf{Euclidean algorithm} on the left column:
	subtract the second row from the first row,
	then three times the first row from the second:
	\[ 
		\begin{pmatrix} 
			18 & 46 \\
			14 & 36
		\end{pmatrix} 
		\mapsto
		\begin{pmatrix} 
			4 & 10 \\
			14 & 36
		\end{pmatrix}
		\mapsto
		\begin{pmatrix} 
			4 & 10 \\
			2 & 6
		\end{pmatrix}.
	\]
	Now that the GCD of $2$ is present, we move it to the upper-left,
	and then kill off all the entries in the same row/column.
	Since $2$ was the GCD all along, we know it divides $10$ and we're done:
	\[
		\begin{pmatrix} 
			4 & 10 \\
			2 & 6
		\end{pmatrix}
		\mapsto
		\begin{pmatrix} 
			2 & 6 \\
			4 & 10
		\end{pmatrix}
		\mapsto 
		\begin{pmatrix} 
			2 & 6 \\
			0 & -2
		\end{pmatrix}
		\mapsto
		\begin{pmatrix} 
			2 & 0 \\
			0 & -2
		\end{pmatrix}.
	\]
\end{example}
\todo{make a $2 \times 3$ matrix}


\begin{proof}
	[Proof of Smith normal form]

	We want to show, by a series of operations (gradually changing the given basis)
	that we can rearrange the matrix into Smith normal form.

	Define $\gcd(x,y)$ to be any generator of the principal ideal $(x,y)$.
	\begin{claim}[``Euclidean algorithm'']
		If $a$ and $b$ are entries in the same row or column,
		we can change bases to replace $a$ with $\gcd(a,b)$.
	\end{claim}
	\begin{subproof}
		We do just the case of columns.
		By hypothesis, $\gcd(a,b) = xa+yb$ for some $x,y \in R$.
		We must have $(x,y) = (1)$ now (we're in a UFD).
		So there are $u$ and $v$ such that $xu + yv = 1$.
		Then
		\[
			\begin{pmatrix} x & y \\ -v & u \end{pmatrix}
			\begin{pmatrix} a \\ b  \end{pmatrix}
			= \begin{pmatrix} \gcd(a,b) \\ \text{something} \end{pmatrix}
		\]
		and the first matrix is invertible (check this!), as desired.
	\end{subproof}
\end{proof}

\section\problemhead
Frobenius normal form

Jordan normal form

\end{document}
